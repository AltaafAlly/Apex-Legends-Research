{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from sklearn.exceptions import ConvergenceWarning  # Importing ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Replace the paths with your actual file paths\n",
    "\n",
    "# Read the CSV files\n",
    "df_xbox = pd.read_csv(path_xbox)\n",
    "df_ps4 = pd.read_csv(path_ps4)\n",
    "df_pc = pd.read_csv(path_pc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine the datasets\n",
    "Career_Stats_df = pd.concat([df_xbox, df_ps4, df_pc], ignore_index=True)\n",
    "\n",
    "# Convert the relevant columns to numeric\n",
    "Career_Stats_df['career_kills'] = pd.to_numeric(Career_Stats_df['career_kills'], errors='coerce')\n",
    "Career_Stats_df['career_wins'] = pd.to_numeric(Career_Stats_df['career_wins'], errors='coerce')\n",
    "Career_Stats_df['career_revives'] = pd.to_numeric(Career_Stats_df['career_revives'], errors='coerce')\n",
    "\n",
    "# Replace 0s with NaN to treat them as missing values\n",
    "Career_Stats_df.replace(0, np.nan, inplace=True)\n",
    "\n",
    "# Drop the player_name column for imputation\n",
    "player_names = Career_Stats_df['player_name']\n",
    "numeric_df = Career_Stats_df.drop(columns=['player_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Suppress iteration warnings for logistic regression convergence\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "print(\"Starting imputation processes...\")\n",
    "\n",
    "# Mode Imputation\n",
    "print(\"Performing Mode Imputation...\")\n",
    "mode_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "df_mode_imputed = pd.DataFrame(mode_imputer.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "df_mode_imputed.insert(0, 'player_name', player_names)\n",
    "print(\"Mode Imputation completed.\")\n",
    "\n",
    "# Logistic Regression Imputation\n",
    "print(\"Performing Logistic Regression Imputation...\")\n",
    "lr_imputer = IterativeImputer(estimator=LogisticRegression(solver='lbfgs'), random_state=42, max_iter=10, verbose=2)\n",
    "df_lr_imputed = pd.DataFrame(lr_imputer.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "df_lr_imputed.insert(0, 'player_name', player_names)\n",
    "print(\"Logistic Regression Imputation completed.\")\n",
    "\n",
    "# Random Forest Imputation\n",
    "print(\"Performing Random Forest Imputation...\")\n",
    "rf_imputer = IterativeImputer(estimator=RandomForestClassifier(n_estimators=10), random_state=42, max_iter=10, verbose=2)\n",
    "df_rf_imputed = pd.DataFrame(rf_imputer.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "df_rf_imputed.insert(0, 'player_name', player_names)\n",
    "print(\"Random Forest Imputation completed.\")\n",
    "\n",
    "# KNN Imputation\n",
    "print(\"Performing KNN Imputation...\")\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "df_knn_imputed = pd.DataFrame(knn_imputer.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "df_knn_imputed.insert(0, 'player_name', player_names)\n",
    "print(\"KNN Imputation completed.\")\n",
    "\n",
    "# Mean Imputation\n",
    "print(\"Performing Mean Imputation...\")\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "df_mean_imputed = pd.DataFrame(mean_imputer.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "df_mean_imputed.insert(0, 'player_name', player_names)\n",
    "print(\"Mean Imputation completed.\")\n",
    "\n",
    "# Median Imputation\n",
    "print(\"Performing Median Imputation...\")\n",
    "median_imputer = SimpleImputer(strategy='median')\n",
    "df_median_imputed = pd.DataFrame(median_imputer.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "df_median_imputed.insert(0, 'player_name', player_names)\n",
    "print(\"Median Imputation completed.\")\n",
    "\n",
    "# XGBoost Imputation\n",
    "print(\"Performing XGBoost Imputation...\")\n",
    "xgb_imputer = IterativeImputer(estimator=XGBRegressor(), random_state=42, max_iter=10, verbose=2)\n",
    "df_xgb_imputed = pd.DataFrame(xgb_imputer.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "df_xgb_imputed.insert(0, 'player_name', player_names)\n",
    "print(\"XGBoost Imputation completed.\")\n",
    "\n",
    "# MICE Imputation\n",
    "print(\"Performing MICE Imputation...\")\n",
    "mice_imputer = IterativeImputer(max_iter=10, random_state=42)\n",
    "df_mice_imputed = pd.DataFrame(mice_imputer.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "df_mice_imputed.insert(0, 'player_name', player_names)\n",
    "print(\"MICE Imputation completed.\")\n",
    "\n",
    "# Dictionary of imputed dataframes\n",
    "imputed_dataframes = {\n",
    "    \"Mode Imputation\": df_mode_imputed,\n",
    "    \"Logistic Regression Imputation\": df_lr_imputed,\n",
    "    \"Random Forest Imputation\": df_rf_imputed,\n",
    "    \"KNN Imputation\": df_knn_imputed,\n",
    "    \"Mean Imputation\": df_mean_imputed,\n",
    "    \"Median Imputation\": df_median_imputed,\n",
    "    \"XGBoost Imputation\": df_xgb_imputed,\n",
    "    \"MICE Imputation\": df_mice_imputed\n",
    "}\n",
    "\n",
    "# Check that there are no missing values\n",
    "print(\"\\nVerifying no missing values after imputation:\")\n",
    "for name, df in imputed_dataframes.items():\n",
    "    missing = df.isnull().sum().sum()\n",
    "    print(f\"{name}: {missing} missing values\")\n",
    "\n",
    "print(\"\\nOriginal dataframe missing values (should be unchanged):\")\n",
    "print(Career_Stats_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot the correlation heatmap\n",
    "def plot_correlation_heatmap(df, title):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\", fmt='.2f')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot scatter matrix\n",
    "def plot_scatter_matrix(df, title):\n",
    "    pd.plotting.scatter_matrix(df, alpha=0.2, figsize=(10, 10), diagonal='kde')\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "# Plot correlation heatmap and scatter plot for original data\n",
    "print(\"Original Data Correlation Heatmap and Scatter Plot:\")\n",
    "plot_correlation_heatmap(numeric_df, \"Correlation Heatmap (Before Imputation)\")\n",
    "plot_scatter_matrix(numeric_df, \"Scatter Plot Matrix (Before Imputation)\")\n",
    "\n",
    "# After Imputation: Visualizing the correlation for each imputed dataframe\n",
    "for name, df in imputed_dataframes.items():\n",
    "    print(f\"\\n{name} Correlation Heatmap and Scatter Plot:\")\n",
    "    \n",
    "    # Drop 'player_name' for correlation matrix\n",
    "    imputed_numeric_df = df.drop(columns=['player_name'])\n",
    "    \n",
    "    # Plot heatmap for the imputed data\n",
    "    plot_correlation_heatmap(imputed_numeric_df, f\"Correlation Heatmap ({name})\")\n",
    "    \n",
    "    # Plot scatter plot for the imputed data\n",
    "    plot_scatter_matrix(imputed_numeric_df, f\"Scatter Plot Matrix ({name})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Round off the values in the MICE-imputed dataframe (excluding 'player_name')\n",
    "df_mice_imputed_rounded = df_mice_imputed.copy()\n",
    "df_mice_imputed_rounded.iloc[:, 1:] = df_mice_imputed_rounded.iloc[:, 1:].round()\n",
    "\n",
    "# save_path = \"path_to_save_rounded_mice_imputed.csv\"  # Specify the path where you want to save the rounded dataframe\n",
    "save_path = \"rounded_mice_imputed.csv\"  # Specify the path where you want to save the rounded dataframe\n",
    "# Ensure the directory exists\n",
    "\n",
    "# Save the rounded MICE-imputed dataframe to the specified file path as a CSV\n",
    "df_mice_imputed_rounded.to_csv(save_path, index=False)\n",
    "\n",
    "print(f\"Rounded MICE-imputed dataset saved to {save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
