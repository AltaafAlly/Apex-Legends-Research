{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Career_Stats_df = pd.read_csv('C:/Users/altaa/Documents/GitHub/Apex-Legends-Research/Data_Retrieval/CSV_files/Career_Stats.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1949 entries, 0 to 1948\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   player_name     1949 non-null   object\n",
      " 1   career_kills    1949 non-null   object\n",
      " 2   career_wins     1949 non-null   object\n",
      " 3   career_revives  1949 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 61.0+ KB\n"
     ]
    }
   ],
   "source": [
    "Career_Stats_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Objects into Numerical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1949 entries, 0 to 1948\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   player_name     1949 non-null   object \n",
      " 1   career_kills    1904 non-null   float64\n",
      " 2   career_wins     973 non-null    float64\n",
      " 3   career_revives  896 non-null    float64\n",
      "dtypes: float64(3), object(1)\n",
      "memory usage: 61.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Convert the relevant columns to numeric\n",
    "Career_Stats_df['career_kills'] = pd.to_numeric(Career_Stats_df['career_kills'], errors='coerce')\n",
    "Career_Stats_df['career_wins'] = pd.to_numeric(Career_Stats_df['career_wins'], errors='coerce')\n",
    "Career_Stats_df['career_revives'] = pd.to_numeric(Career_Stats_df['career_revives'], errors='coerce')\n",
    "#Randomize data\n",
    "Career_Stats_df = Career_Stats_df.sample(frac=1).reset_index(drop=True)\n",
    "# Print the data types to verify the changes\n",
    "Career_Stats_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673d2d43ac90408ca46a9d57d683b9be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8a31edc945f43c2876fb5991c8a867c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef74bd79d10490ca7d0558553d9f0c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f047b5bb32f848eb8cb1f54eaca49413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_report = ProfileReport(Career_Stats_df, minimal=True)\n",
    "df_report.to_file(output_file='Career_Stats.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Unnecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 0s with NaN to treat them as missing values\n",
    "Career_Stats_df.replace(0, np.nan, inplace=True)\n",
    "\n",
    "# Drop the player_name column\n",
    "player_names = Career_Stats_df['player_name']\n",
    "numeric_df = Career_Stats_df.drop(columns=['player_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Imputation(filling in missing values using different techniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "49/49 - 2s - 35ms/step - loss: 2140393344.0000 - val_loss: 96302120.0000\n",
      "Epoch 2/100\n",
      "49/49 - 0s - 2ms/step - loss: 29485300.0000 - val_loss: 6191005.5000\n",
      "Epoch 3/100\n",
      "49/49 - 0s - 2ms/step - loss: 8587297.0000 - val_loss: 8043790.5000\n",
      "Epoch 4/100\n",
      "49/49 - 0s - 2ms/step - loss: 7987022.5000 - val_loss: 6086750.5000\n",
      "Epoch 5/100\n",
      "49/49 - 0s - 2ms/step - loss: 7434284.0000 - val_loss: 6652602.0000\n",
      "Epoch 6/100\n",
      "49/49 - 0s - 2ms/step - loss: 6542262.5000 - val_loss: 5193589.5000\n",
      "Epoch 7/100\n",
      "49/49 - 0s - 2ms/step - loss: 5649806.5000 - val_loss: 4374761.0000\n",
      "Epoch 8/100\n",
      "49/49 - 0s - 2ms/step - loss: 3770512.5000 - val_loss: 991496.3125\n",
      "Epoch 9/100\n",
      "49/49 - 0s - 2ms/step - loss: 1071908.3750 - val_loss: 582182.6875\n",
      "Epoch 10/100\n",
      "49/49 - 0s - 2ms/step - loss: 852976.1250 - val_loss: 585525.9375\n",
      "Epoch 11/100\n",
      "49/49 - 0s - 2ms/step - loss: 793351.2500 - val_loss: 581620.0000\n",
      "Epoch 12/100\n",
      "49/49 - 0s - 2ms/step - loss: 755521.6875 - val_loss: 531897.3750\n",
      "Epoch 13/100\n",
      "49/49 - 0s - 2ms/step - loss: 715391.4375 - val_loss: 722102.1250\n",
      "Epoch 14/100\n",
      "49/49 - 0s - 2ms/step - loss: 665475.5000 - val_loss: 431351.2500\n",
      "Epoch 15/100\n",
      "49/49 - 0s - 2ms/step - loss: 590526.5000 - val_loss: 477851.4375\n",
      "Epoch 16/100\n",
      "49/49 - 0s - 2ms/step - loss: 527039.0625 - val_loss: 439876.4688\n",
      "Epoch 17/100\n",
      "49/49 - 0s - 2ms/step - loss: 483516.5625 - val_loss: 342277.4688\n",
      "Epoch 18/100\n",
      "49/49 - 0s - 2ms/step - loss: 413788.1250 - val_loss: 442987.5312\n",
      "Epoch 19/100\n",
      "49/49 - 0s - 2ms/step - loss: 383100.1562 - val_loss: 212740.9219\n",
      "Epoch 20/100\n",
      "49/49 - 0s - 2ms/step - loss: 264925.7500 - val_loss: 200553.7812\n",
      "Epoch 21/100\n",
      "49/49 - 0s - 2ms/step - loss: 169790.9375 - val_loss: 120031.9375\n",
      "Epoch 22/100\n",
      "49/49 - 0s - 2ms/step - loss: 79150.6484 - val_loss: 33457.4219\n",
      "Epoch 23/100\n",
      "49/49 - 0s - 2ms/step - loss: 29145.3105 - val_loss: 6671.6406\n",
      "Epoch 24/100\n",
      "49/49 - 0s - 2ms/step - loss: 9632.7998 - val_loss: 1970.0659\n",
      "Epoch 25/100\n",
      "49/49 - 0s - 2ms/step - loss: 5900.1821 - val_loss: 1917.6266\n",
      "Epoch 26/100\n",
      "49/49 - 0s - 2ms/step - loss: 5519.0107 - val_loss: 2521.3752\n",
      "Epoch 27/100\n",
      "49/49 - 0s - 2ms/step - loss: 5378.5415 - val_loss: 1170.7993\n",
      "Epoch 28/100\n",
      "49/49 - 0s - 3ms/step - loss: 5172.0972 - val_loss: 794.4214\n",
      "Epoch 29/100\n",
      "49/49 - 0s - 2ms/step - loss: 3791.9673 - val_loss: 2162.5996\n",
      "Epoch 30/100\n",
      "49/49 - 0s - 3ms/step - loss: 31175.0820 - val_loss: 2598.6887\n",
      "Epoch 31/100\n",
      "49/49 - 0s - 2ms/step - loss: 14908.1836 - val_loss: 1097.8533\n",
      "Epoch 32/100\n",
      "49/49 - 0s - 2ms/step - loss: 2755.6648 - val_loss: 1143.8419\n",
      "Epoch 33/100\n",
      "49/49 - 0s - 3ms/step - loss: 1944.9001 - val_loss: 655.7391\n",
      "Epoch 34/100\n",
      "49/49 - 0s - 2ms/step - loss: 1806.5234 - val_loss: 649.7453\n",
      "Epoch 35/100\n",
      "49/49 - 0s - 2ms/step - loss: 1807.4978 - val_loss: 789.5901\n",
      "Epoch 36/100\n",
      "49/49 - 0s - 2ms/step - loss: 1509.8871 - val_loss: 590.4348\n",
      "Epoch 37/100\n",
      "49/49 - 0s - 2ms/step - loss: 1660.8542 - val_loss: 675.6318\n",
      "Epoch 38/100\n",
      "49/49 - 0s - 2ms/step - loss: 1437.0824 - val_loss: 904.6974\n",
      "Epoch 39/100\n",
      "49/49 - 0s - 3ms/step - loss: 1654.9794 - val_loss: 698.6905\n",
      "Epoch 40/100\n",
      "49/49 - 0s - 2ms/step - loss: 1510.6949 - val_loss: 946.9993\n",
      "Epoch 41/100\n",
      "49/49 - 0s - 2ms/step - loss: 1557.3575 - val_loss: 1344.4768\n",
      "Epoch 42/100\n",
      "49/49 - 0s - 2ms/step - loss: 2231.9102 - val_loss: 943.7151\n",
      "Epoch 43/100\n",
      "49/49 - 0s - 2ms/step - loss: 2247.6538 - val_loss: 536.1128\n",
      "Epoch 44/100\n",
      "49/49 - 0s - 2ms/step - loss: 1502.1046 - val_loss: 1879.0846\n",
      "Epoch 45/100\n",
      "49/49 - 0s - 2ms/step - loss: 1621.6072 - val_loss: 523.0184\n",
      "Epoch 46/100\n",
      "49/49 - 0s - 2ms/step - loss: 2930.6624 - val_loss: 1948.2094\n",
      "Epoch 47/100\n",
      "49/49 - 0s - 2ms/step - loss: 10372.6816 - val_loss: 1739.3282\n",
      "Epoch 48/100\n",
      "49/49 - 0s - 2ms/step - loss: 1476.6487 - val_loss: 536.2006\n",
      "Epoch 49/100\n",
      "49/49 - 0s - 2ms/step - loss: 1579.2504 - val_loss: 970.1766\n",
      "Epoch 50/100\n",
      "49/49 - 0s - 2ms/step - loss: 1239.4089 - val_loss: 682.7869\n",
      "Epoch 51/100\n",
      "49/49 - 0s - 2ms/step - loss: 1256.8286 - val_loss: 554.4843\n",
      "Epoch 52/100\n",
      "49/49 - 0s - 2ms/step - loss: 1593.3496 - val_loss: 893.7831\n",
      "Epoch 53/100\n",
      "49/49 - 0s - 2ms/step - loss: 1062.7319 - val_loss: 480.5096\n",
      "Epoch 54/100\n",
      "49/49 - 0s - 2ms/step - loss: 1628.6105 - val_loss: 1397.9817\n",
      "Epoch 55/100\n",
      "49/49 - 0s - 2ms/step - loss: 1637.6898 - val_loss: 820.1464\n",
      "Epoch 56/100\n",
      "49/49 - 0s - 2ms/step - loss: 1191.7452 - val_loss: 1336.1873\n",
      "Epoch 57/100\n",
      "49/49 - 0s - 2ms/step - loss: 2359.0630 - val_loss: 672.5094\n",
      "Epoch 58/100\n",
      "49/49 - 0s - 2ms/step - loss: 1086.1583 - val_loss: 652.1496\n",
      "Epoch 59/100\n",
      "49/49 - 0s - 2ms/step - loss: 1319.3947 - val_loss: 486.4149\n",
      "Epoch 60/100\n",
      "49/49 - 0s - 3ms/step - loss: 1373.6360 - val_loss: 869.1173\n",
      "Epoch 61/100\n",
      "49/49 - 0s - 2ms/step - loss: 1835.9286 - val_loss: 486.1216\n",
      "Epoch 62/100\n",
      "49/49 - 0s - 2ms/step - loss: 4423.0405 - val_loss: 586.4975\n",
      "Epoch 63/100\n",
      "49/49 - 0s - 3ms/step - loss: 1236.7230 - val_loss: 971.1642\n",
      "Epoch 64/100\n",
      "49/49 - 0s - 2ms/step - loss: 1438.8508 - val_loss: 682.1934\n",
      "Epoch 65/100\n",
      "49/49 - 0s - 2ms/step - loss: 1403.4958 - val_loss: 1348.8009\n",
      "Epoch 66/100\n",
      "49/49 - 0s - 2ms/step - loss: 2118.2549 - val_loss: 569.9874\n",
      "Epoch 67/100\n",
      "49/49 - 0s - 2ms/step - loss: 687.9297 - val_loss: 581.4041\n",
      "Epoch 68/100\n",
      "49/49 - 0s - 2ms/step - loss: 1156.3394 - val_loss: 680.9231\n",
      "Epoch 69/100\n",
      "49/49 - 0s - 2ms/step - loss: 3767.8950 - val_loss: 4096.8560\n",
      "Epoch 70/100\n",
      "49/49 - 0s - 3ms/step - loss: 3549.6289 - val_loss: 853.4424\n",
      "Epoch 71/100\n",
      "49/49 - 0s - 2ms/step - loss: 2447.1746 - val_loss: 1992.2991\n",
      "Epoch 72/100\n",
      "49/49 - 0s - 2ms/step - loss: 9177.2783 - val_loss: 2158.5620\n",
      "Epoch 73/100\n",
      "49/49 - 0s - 2ms/step - loss: 4578.3042 - val_loss: 3228.5430\n",
      "Epoch 74/100\n",
      "49/49 - 0s - 2ms/step - loss: 2098.6172 - val_loss: 568.6182\n",
      "Epoch 75/100\n",
      "49/49 - 0s - 2ms/step - loss: 1528.7877 - val_loss: 2051.2253\n",
      "Epoch 76/100\n",
      "49/49 - 0s - 2ms/step - loss: 1840.2892 - val_loss: 1332.8073\n",
      "Epoch 77/100\n",
      "49/49 - 0s - 2ms/step - loss: 2230.8882 - val_loss: 535.8206\n",
      "Epoch 78/100\n",
      "49/49 - 0s - 2ms/step - loss: 3494.6194 - val_loss: 4066.0828\n",
      "Epoch 79/100\n",
      "49/49 - 0s - 2ms/step - loss: 1531.1101 - val_loss: 461.1315\n",
      "Epoch 80/100\n",
      "49/49 - 0s - 2ms/step - loss: 1974.1222 - val_loss: 1895.7046\n",
      "Epoch 81/100\n",
      "49/49 - 0s - 2ms/step - loss: 138825.3281 - val_loss: 23995.7734\n",
      "Epoch 82/100\n",
      "49/49 - 0s - 2ms/step - loss: 30496.9902 - val_loss: 1206.1764\n",
      "Epoch 83/100\n",
      "49/49 - 0s - 2ms/step - loss: 2881.0764 - val_loss: 357.3232\n",
      "Epoch 84/100\n",
      "49/49 - 0s - 2ms/step - loss: 1029.3889 - val_loss: 2960.7183\n",
      "Epoch 85/100\n",
      "49/49 - 0s - 2ms/step - loss: 3675.5278 - val_loss: 5963.2710\n",
      "Epoch 86/100\n",
      "49/49 - 0s - 2ms/step - loss: 5418.0591 - val_loss: 324.6490\n",
      "Epoch 87/100\n",
      "49/49 - 0s - 2ms/step - loss: 1338.5674 - val_loss: 1157.0950\n",
      "Epoch 88/100\n",
      "49/49 - 0s - 2ms/step - loss: 2349.7615 - val_loss: 472.4035\n",
      "Epoch 89/100\n",
      "49/49 - 0s - 2ms/step - loss: 1401.0645 - val_loss: 864.1514\n",
      "Epoch 90/100\n",
      "49/49 - 0s - 2ms/step - loss: 803.9796 - val_loss: 449.9722\n",
      "Epoch 91/100\n",
      "49/49 - 0s - 2ms/step - loss: 546.6675 - val_loss: 415.5634\n",
      "Epoch 92/100\n",
      "49/49 - 0s - 2ms/step - loss: 629.2420 - val_loss: 985.4402\n",
      "Epoch 93/100\n",
      "49/49 - 0s - 2ms/step - loss: 1403.8528 - val_loss: 737.3353\n",
      "Epoch 94/100\n",
      "49/49 - 0s - 2ms/step - loss: 2698.9124 - val_loss: 2714.8123\n",
      "Epoch 95/100\n",
      "49/49 - 0s - 2ms/step - loss: 1064.2191 - val_loss: 398.6605\n",
      "Epoch 96/100\n",
      "49/49 - 0s - 2ms/step - loss: 968.6116 - val_loss: 979.8260\n",
      "Epoch 97/100\n",
      "49/49 - 0s - 2ms/step - loss: 6704.7246 - val_loss: 2046.7452\n",
      "Epoch 98/100\n",
      "49/49 - 0s - 2ms/step - loss: 7878.8853 - val_loss: 444.0474\n",
      "Epoch 99/100\n",
      "49/49 - 0s - 2ms/step - loss: 1980.3385 - val_loss: 1842.2051\n",
      "Epoch 100/100\n",
      "49/49 - 0s - 2ms/step - loss: 1322.9047 - val_loss: 876.9322\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Imputed dataset saved to 'Data_Retrieval/CSV_files/Career_Stats_autoencoder_imputed.csv'\n"
     ]
    }
   ],
   "source": [
    "# Fill initial missing values with column mean for training\n",
    "numeric_df_imputed = numeric_df.fillna(numeric_df.mean())\n",
    "\n",
    "# Define an autoencoder model\n",
    "def build_autoencoder(input_dim):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoded = Dense(64, activation='relu')(input_layer)\n",
    "    encoded = Dense(32, activation='relu')(encoded)\n",
    "    encoded = Dense(16, activation='relu')(encoded)\n",
    "    decoded = Dense(32, activation='relu')(encoded)\n",
    "    decoded = Dense(64, activation='relu')(decoded)\n",
    "    output_layer = Dense(input_dim, activation='linear')(decoded)\n",
    "    autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "    autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return autoencoder\n",
    "\n",
    "# Prepare the data for the autoencoder\n",
    "X_train_ae = numeric_df_imputed.values\n",
    "\n",
    "# Build and train the autoencoder\n",
    "input_dim = X_train_ae.shape[1]\n",
    "autoencoder = build_autoencoder(input_dim)\n",
    "autoencoder.fit(X_train_ae, X_train_ae, epochs=100, batch_size=32, validation_split=0.2, verbose=2)\n",
    "\n",
    "# Use the trained autoencoder to fill missing values\n",
    "encoded_data = autoencoder.predict(X_train_ae)\n",
    "\n",
    "# Create the imputed dataframe\n",
    "df_autoencoder_imputed = pd.DataFrame(encoded_data, columns=numeric_df.columns)\n",
    "df_autoencoder_imputed.insert(0, 'player_name', player_names)\n",
    "\n",
    "# Save the imputed dataframe to a CSV file\n",
    "df_autoencoder_imputed.to_csv('C:/Users/altaa/Documents/GitHub/Apex-Legends-Research/Data_Retrieval/py_files/Notebook_For_Data_Preprocessing/Career_Stats_autoencoder_imputed.csv', index=False)\n",
    "\n",
    "print(\"Imputed dataset saved to 'Data_Retrieval/CSV_files/Career_Stats_autoencoder_imputed.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting imputation processes...\n",
      "Performing Mode Imputation...\n",
      "Mode Imputation completed.\n",
      "Performing Logistic Regression Imputation...\n",
      "[IterativeImputer] Completing matrix with shape (1949, 3)\n",
      "[IterativeImputer] Ending imputation round 1/10, elapsed time 11.60\n",
      "[IterativeImputer] Change: 51138.98274505395, scaled tolerance: 371.099 \n",
      "[IterativeImputer] Ending imputation round 2/10, elapsed time 24.02\n",
      "[IterativeImputer] Change: 50193.0, scaled tolerance: 371.099 \n",
      "[IterativeImputer] Ending imputation round 3/10, elapsed time 36.15\n",
      "[IterativeImputer] Change: 49867.0, scaled tolerance: 371.099 \n",
      "[IterativeImputer] Ending imputation round 4/10, elapsed time 49.74\n",
      "[IterativeImputer] Change: 54446.0, scaled tolerance: 371.099 \n",
      "[IterativeImputer] Ending imputation round 5/10, elapsed time 61.86\n",
      "[IterativeImputer] Change: 69801.0, scaled tolerance: 371.099 \n",
      "[IterativeImputer] Ending imputation round 6/10, elapsed time 74.59\n",
      "[IterativeImputer] Change: 57528.0, scaled tolerance: 371.099 \n",
      "[IterativeImputer] Ending imputation round 7/10, elapsed time 87.88\n",
      "[IterativeImputer] Change: 53793.0, scaled tolerance: 371.099 \n",
      "[IterativeImputer] Ending imputation round 8/10, elapsed time 99.77\n",
      "[IterativeImputer] Change: 55403.0, scaled tolerance: 371.099 \n",
      "[IterativeImputer] Ending imputation round 9/10, elapsed time 111.47\n",
      "[IterativeImputer] Change: 55054.0, scaled tolerance: 371.099 \n",
      "[IterativeImputer] Ending imputation round 10/10, elapsed time 122.63\n",
      "[IterativeImputer] Change: 290674.0, scaled tolerance: 371.099 \n",
      "Logistic Regression Imputation completed.\n",
      "Performing Random Forest Imputation...\n",
      "[IterativeImputer] Completing matrix with shape (1949, 3)\n",
      "[IterativeImputer] Ending imputation round 1/10, elapsed time 1.51\n",
      "[IterativeImputer] Change: 57023.98274505396, scaled tolerance: 371.099 \n",
      "[IterativeImputer] Ending imputation round 2/10, elapsed time 3.00\n",
      "[IterativeImputer] Change: 32940.0, scaled tolerance: 371.099 \n",
      "[IterativeImputer] Ending imputation round 3/10, elapsed time 4.63\n",
      "[IterativeImputer] Change: 34712.0, scaled tolerance: 371.099 \n",
      "[IterativeImputer] Ending imputation round 4/10, elapsed time 6.27\n",
      "[IterativeImputer] Change: 33989.0, scaled tolerance: 371.099 \n",
      "[IterativeImputer] Ending imputation round 5/10, elapsed time 8.07\n",
      "[IterativeImputer] Change: 36507.0, scaled tolerance: 371.099 \n",
      "[IterativeImputer] Ending imputation round 6/10, elapsed time 9.82\n",
      "[IterativeImputer] Change: 36507.0, scaled tolerance: 371.099 \n",
      "[IterativeImputer] Ending imputation round 7/10, elapsed time 11.50\n",
      "[IterativeImputer] Change: 36507.0, scaled tolerance: 371.099 \n",
      "[IterativeImputer] Ending imputation round 8/10, elapsed time 13.26\n",
      "[IterativeImputer] Change: 36507.0, scaled tolerance: 371.099 \n",
      "[IterativeImputer] Ending imputation round 9/10, elapsed time 15.03\n",
      "[IterativeImputer] Change: 36507.0, scaled tolerance: 371.099 \n",
      "[IterativeImputer] Ending imputation round 10/10, elapsed time 16.68\n",
      "[IterativeImputer] Change: 21025.0, scaled tolerance: 371.099 \n",
      "Random Forest Imputation completed.\n",
      "Performing KNN Imputation...\n",
      "KNN Imputation completed.\n",
      "Performing Mean Imputation...\n",
      "Mean Imputation completed.\n",
      "Performing Median Imputation...\n",
      "Median Imputation completed.\n",
      "Performing XGBoost Imputation...\n",
      "[IterativeImputer] Completing matrix with shape (1949, 3)\n",
      "[IterativeImputer] Ending imputation round 1/10, elapsed time 0.23\n",
      "[IterativeImputer] Change: 43737.97200286645, scaled tolerance: 371.099 \n",
      "[IterativeImputer] Ending imputation round 2/10, elapsed time 0.48\n",
      "[IterativeImputer] Change: 15442.7294921875, scaled tolerance: 371.099 \n",
      "[IterativeImputer] Ending imputation round 3/10, elapsed time 0.74\n",
      "[IterativeImputer] Change: 17163.79296875, scaled tolerance: 371.099 \n",
      "[IterativeImputer] Ending imputation round 4/10, elapsed time 1.01\n",
      "[IterativeImputer] Change: 22254.9609375, scaled tolerance: 371.099 \n",
      "[IterativeImputer] Ending imputation round 5/10, elapsed time 1.34\n",
      "[IterativeImputer] Change: 42807.9951171875, scaled tolerance: 371.099 \n",
      "[IterativeImputer] Ending imputation round 6/10, elapsed time 1.66\n",
      "[IterativeImputer] Change: 19022.45703125, scaled tolerance: 371.099 \n",
      "[IterativeImputer] Ending imputation round 7/10, elapsed time 1.92\n",
      "[IterativeImputer] Change: 74747.73193359375, scaled tolerance: 371.099 \n",
      "[IterativeImputer] Ending imputation round 8/10, elapsed time 2.13\n",
      "[IterativeImputer] Change: 26067.6923828125, scaled tolerance: 371.099 \n",
      "[IterativeImputer] Ending imputation round 9/10, elapsed time 2.35\n",
      "[IterativeImputer] Change: 27368.9541015625, scaled tolerance: 371.099 \n",
      "[IterativeImputer] Ending imputation round 10/10, elapsed time 2.55\n",
      "[IterativeImputer] Change: 22045.3466796875, scaled tolerance: 371.099 \n",
      "XGBoost Imputation completed.\n",
      "Performing MICE Imputation...\n",
      "MICE Imputation completed.\n",
      "\n",
      "Verifying no missing values after imputation:\n",
      "Mode Imputation: 0 missing values\n",
      "Logistic Regression Imputation: 0 missing values\n",
      "Random Forest Imputation: 0 missing values\n",
      "KNN Imputation: 0 missing values\n",
      "Mean Imputation: 0 missing values\n",
      "Median Imputation: 0 missing values\n",
      "XGBoost Imputation: 0 missing values\n",
      "MICE Imputation: 0 missing values\n",
      "\n",
      "Original dataframe missing values (should be unchanged):\n",
      "player_name          0\n",
      "career_kills        45\n",
      "career_wins        976\n",
      "career_revives    1053\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Suppress iteration warnings for logistic regression convergence\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "print(\"Starting imputation processes...\")\n",
    "\n",
    "# Mode Imputation\n",
    "print(\"Performing Mode Imputation...\")\n",
    "mode_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "df_mode_imputed = pd.DataFrame(mode_imputer.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "df_mode_imputed.insert(0, 'player_name', player_names)\n",
    "print(\"Mode Imputation completed.\")\n",
    "\n",
    "# Logistic Regression Imputation\n",
    "print(\"Performing Logistic Regression Imputation...\")\n",
    "lr_imputer = IterativeImputer(estimator=LogisticRegression(solver='lbfgs'), random_state=42, max_iter=10, verbose=2)\n",
    "df_lr_imputed = pd.DataFrame(lr_imputer.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "df_lr_imputed.insert(0, 'player_name', player_names)\n",
    "print(\"Logistic Regression Imputation completed.\")\n",
    "\n",
    "# Random Forest Imputation\n",
    "print(\"Performing Random Forest Imputation...\")\n",
    "rf_imputer = IterativeImputer(estimator=RandomForestClassifier(n_estimators=10), random_state=42, max_iter=10, verbose=2)\n",
    "df_rf_imputed = pd.DataFrame(rf_imputer.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "df_rf_imputed.insert(0, 'player_name', player_names)\n",
    "print(\"Random Forest Imputation completed.\")\n",
    "\n",
    "# KNN Imputation\n",
    "print(\"Performing KNN Imputation...\")\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "df_knn_imputed = pd.DataFrame(knn_imputer.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "df_knn_imputed.insert(0, 'player_name', player_names)\n",
    "print(\"KNN Imputation completed.\")\n",
    "\n",
    "# Mean Imputation\n",
    "print(\"Performing Mean Imputation...\")\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "df_mean_imputed = pd.DataFrame(mean_imputer.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "df_mean_imputed.insert(0, 'player_name', player_names)\n",
    "print(\"Mean Imputation completed.\")\n",
    "\n",
    "# Median Imputation\n",
    "print(\"Performing Median Imputation...\")\n",
    "median_imputer = SimpleImputer(strategy='median')\n",
    "df_median_imputed = pd.DataFrame(median_imputer.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "df_median_imputed.insert(0, 'player_name', player_names)\n",
    "print(\"Median Imputation completed.\")\n",
    "\n",
    "# XGBoost Imputation\n",
    "print(\"Performing XGBoost Imputation...\")\n",
    "xgb_imputer = IterativeImputer(estimator=XGBRegressor(), random_state=42, max_iter=10, verbose=2)\n",
    "df_xgb_imputed = pd.DataFrame(xgb_imputer.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "df_xgb_imputed.insert(0, 'player_name', player_names)\n",
    "print(\"XGBoost Imputation completed.\")\n",
    "\n",
    "# MICE Imputation\n",
    "print(\"Performing MICE Imputation...\")\n",
    "mice_imputer = IterativeImputer(max_iter=10, random_state=42)\n",
    "df_mice_imputed = pd.DataFrame(mice_imputer.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "df_mice_imputed.insert(0, 'player_name', player_names)\n",
    "print(\"MICE Imputation completed.\")\n",
    "\n",
    "# Dictionary of imputed dataframes\n",
    "imputed_dataframes = {\n",
    "    \"Mode Imputation\": df_mode_imputed,\n",
    "    \"Logistic Regression Imputation\": df_lr_imputed,\n",
    "    \"Random Forest Imputation\": df_rf_imputed,\n",
    "    \"KNN Imputation\": df_knn_imputed,\n",
    "    \"Mean Imputation\": df_mean_imputed,\n",
    "    \"Median Imputation\": df_median_imputed,\n",
    "    \"XGBoost Imputation\": df_xgb_imputed,\n",
    "    \"MICE Imputation\": df_mice_imputed\n",
    "}\n",
    "\n",
    "# Check that there are no missing values\n",
    "print(\"\\nVerifying no missing values after imputation:\")\n",
    "for name, df in imputed_dataframes.items():\n",
    "    missing = df.isnull().sum().sum()\n",
    "    print(f\"{name}: {missing} missing values\")\n",
    "\n",
    "print(\"\\nOriginal dataframe missing values (should be unchanged):\")\n",
    "print(Career_Stats_df.isnull().sum())\n",
    "\n",
    "# Optionally save the imputed dataframes to CSV files\n",
    "df_mode_imputed.to_csv('C:/Users/altaa/Documents/GitHub/Apex-Legends-Research/Data_Retrieval/py_files/Notebook_For_Data_Preprocessing/Career_Stats_mode_imputed.csv', index=False)\n",
    "df_lr_imputed.to_csv('C:/Users/altaa/Documents/GitHub/Apex-Legends-Research/Data_Retrieval/py_files/Notebook_For_Data_Preprocessing/Career_Stats_lr_imputed.csv', index=False)\n",
    "df_rf_imputed.to_csv('C:/Users/altaa/Documents/GitHub/Apex-Legends-Research/Data_Retrieval/py_files/Notebook_For_Data_Preprocessing/Career_Stats_rf_imputed.csv', index=False)\n",
    "df_knn_imputed.to_csv('C:/Users/altaa/Documents/GitHub/Apex-Legends-Research/Data_Retrieval/py_files/Notebook_For_Data_Preprocessing/Career_Stats_knn_imputed.csv', index=False)\n",
    "df_mean_imputed.to_csv('C:/Users/altaa/Documents/GitHub/Apex-Legends-Research/Data_Retrieval/py_files/Notebook_For_Data_Preprocessing/Career_Stats_mean_imputed.csv', index=False)\n",
    "df_median_imputed.to_csv('C:/Users/altaa/Documents/GitHub/Apex-Legends-Research/Data_Retrieval/py_files/Notebook_For_Data_Preprocessing/Career_Stats_median_imputed.csv', index=False)\n",
    "df_xgb_imputed.to_csv('C:/Users/altaa/Documents/GitHub/Apex-Legends-Research/Data_Retrieval/py_files/Notebook_For_Data_Preprocessing/Career_Stats_xgb_imputed.csv', index=False)\n",
    "df_mice_imputed.to_csv('C:/Users/altaa/Documents/GitHub/Apex-Legends-Research/Data_Retrieval/py_files/Notebook_For_Data_Preprocessing/Career_Stats_mice_imputed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model on each imputed dataset to see which dataset is the best and running for each stat as the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running models on Mode Imputation data:\n",
      "  Predicting career_kills...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000094 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 95757.116100\n",
      "  Predicting career_wins...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000076 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 5735.182168\n",
      "  Predicting career_revives...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 11948.336113\n",
      "\n",
      "Running models on Logistic Regression Imputation data:\n",
      "  Predicting career_kills...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 102646.279025\n",
      "  Predicting career_wins...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 9444.347017\n",
      "  Predicting career_revives...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000061 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 16769.253368\n",
      "\n",
      "Running models on Random Forest Imputation data:\n",
      "  Predicting career_kills...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 508\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96583.354073\n",
      "  Predicting career_wins...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 508\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6251.757537\n",
      "  Predicting career_revives...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13424.232842\n",
      "\n",
      "Running models on KNN Imputation data:\n",
      "  Predicting career_kills...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96489.146172\n",
      "  Predicting career_wins...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6385.484622\n",
      "  Predicting career_revives...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000068 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13829.190437\n",
      "\n",
      "Running models on Mean Imputation data:\n",
      "  Predicting career_kills...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96489.146172\n",
      "  Predicting career_wins...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000071 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6514.751541\n",
      "  Predicting career_revives...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13760.546551\n",
      "\n",
      "Running models on Median Imputation data:\n",
      "  Predicting career_kills...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96335.390635\n",
      "  Predicting career_wins...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6309.203977\n",
      "  Predicting career_revives...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 12920.323605\n",
      "\n",
      "Running models on XGBoost Imputation data:\n",
      "  Predicting career_kills...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96296.981699\n",
      "  Predicting career_wins...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000063 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6443.974500\n",
      "  Predicting career_revives...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13954.004109\n",
      "\n",
      "Running models on MICE Imputation data:\n",
      "  Predicting career_kills...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96489.146172\n",
      "  Predicting career_wins...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6383.982488\n",
      "  Predicting career_revives...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13781.652462\n",
      "\n",
      "Results for Mode Imputation:\n",
      "  Target: career_kills\n",
      "    Random Forest: 0.1464\n",
      "    Extra Trees Regressor: 0.0744\n",
      "    Gradient Boosting: 0.1880\n",
      "    Hist Gradient Boosting: 0.1678\n",
      "    Linear Regression: 0.1826\n",
      "    Ridge Regression: 0.1826\n",
      "    Lasso Regression: 0.1826\n",
      "    ElasticNet Regression: 0.1826\n",
      "    Support Vector Regressor: -0.0965\n",
      "    K-Neighbors Regressor: 0.1832\n",
      "    Decision Tree Regressor: -0.0581\n",
      "    AdaBoost Regressor: 0.1930\n",
      "    LightGBM Regressor: 0.1738\n",
      "    XGBoost Regressor: 0.0758\n",
      "  Target: career_wins\n",
      "    Random Forest: 0.0859\n",
      "    Extra Trees Regressor: -0.1237\n",
      "    Gradient Boosting: 0.1852\n",
      "    Hist Gradient Boosting: 0.2210\n",
      "    Linear Regression: 0.2281\n",
      "    Ridge Regression: 0.2281\n",
      "    Lasso Regression: 0.2281\n",
      "    ElasticNet Regression: 0.2281\n",
      "    Support Vector Regressor: -0.1815\n",
      "    K-Neighbors Regressor: 0.1268\n",
      "    Decision Tree Regressor: -0.4327\n",
      "    AdaBoost Regressor: 0.1403\n",
      "    LightGBM Regressor: 0.2410\n",
      "    XGBoost Regressor: 0.0488\n",
      "  Target: career_revives\n",
      "    Random Forest: -0.3513\n",
      "    Extra Trees Regressor: -0.4291\n",
      "    Gradient Boosting: -0.1065\n",
      "    Hist Gradient Boosting: -0.2142\n",
      "    Linear Regression: 0.0139\n",
      "    Ridge Regression: 0.0139\n",
      "    Lasso Regression: 0.0139\n",
      "    ElasticNet Regression: 0.0139\n",
      "    Support Vector Regressor: -0.1430\n",
      "    K-Neighbors Regressor: -0.2328\n",
      "    Decision Tree Regressor: -1.1080\n",
      "    AdaBoost Regressor: -1.2728\n",
      "    LightGBM Regressor: -0.1579\n",
      "    XGBoost Regressor: -0.5360\n",
      "\n",
      "Results for Logistic Regression Imputation:\n",
      "  Target: career_kills\n",
      "    Random Forest: 0.8951\n",
      "    Extra Trees Regressor: 0.8822\n",
      "    Gradient Boosting: 0.8774\n",
      "    Hist Gradient Boosting: 0.8889\n",
      "    Linear Regression: 0.0999\n",
      "    Ridge Regression: 0.0999\n",
      "    Lasso Regression: 0.0999\n",
      "    ElasticNet Regression: 0.0999\n",
      "    Support Vector Regressor: -0.0886\n",
      "    K-Neighbors Regressor: 0.8082\n",
      "    Decision Tree Regressor: 0.8419\n",
      "    AdaBoost Regressor: 0.7329\n",
      "    LightGBM Regressor: 0.8895\n",
      "    XGBoost Regressor: 0.8828\n",
      "  Target: career_wins\n",
      "    Random Forest: 0.6821\n",
      "    Extra Trees Regressor: 0.7010\n",
      "    Gradient Boosting: 0.6463\n",
      "    Hist Gradient Boosting: 0.6907\n",
      "    Linear Regression: 0.1180\n",
      "    Ridge Regression: 0.1180\n",
      "    Lasso Regression: 0.1180\n",
      "    ElasticNet Regression: 0.1180\n",
      "    Support Vector Regressor: -0.0613\n",
      "    K-Neighbors Regressor: 0.5519\n",
      "    Decision Tree Regressor: 0.5215\n",
      "    AdaBoost Regressor: 0.3549\n",
      "    LightGBM Regressor: 0.6828\n",
      "    XGBoost Regressor: 0.6248\n",
      "  Target: career_revives\n",
      "    Random Forest: 0.2875\n",
      "    Extra Trees Regressor: 0.3371\n",
      "    Gradient Boosting: 0.2643\n",
      "    Hist Gradient Boosting: 0.3486\n",
      "    Linear Regression: 0.0417\n",
      "    Ridge Regression: 0.0417\n",
      "    Lasso Regression: 0.0417\n",
      "    ElasticNet Regression: 0.0417\n",
      "    Support Vector Regressor: -0.1786\n",
      "    K-Neighbors Regressor: 0.1548\n",
      "    Decision Tree Regressor: -0.2422\n",
      "    AdaBoost Regressor: 0.0717\n",
      "    LightGBM Regressor: 0.3396\n",
      "    XGBoost Regressor: 0.2011\n",
      "\n",
      "Results for Random Forest Imputation:\n",
      "  Target: career_kills\n",
      "    Random Forest: 0.7050\n",
      "    Extra Trees Regressor: 0.7545\n",
      "    Gradient Boosting: 0.6285\n",
      "    Hist Gradient Boosting: 0.6719\n",
      "    Linear Regression: 0.5430\n",
      "    Ridge Regression: 0.5430\n",
      "    Lasso Regression: 0.5430\n",
      "    ElasticNet Regression: 0.5430\n",
      "    Support Vector Regressor: -0.0928\n",
      "    K-Neighbors Regressor: 0.6690\n",
      "    Decision Tree Regressor: 0.5534\n",
      "    AdaBoost Regressor: 0.4920\n",
      "    LightGBM Regressor: 0.7072\n",
      "    XGBoost Regressor: 0.6788\n",
      "  Target: career_wins\n",
      "    Random Forest: 0.7152\n",
      "    Extra Trees Regressor: 0.7346\n",
      "    Gradient Boosting: 0.6296\n",
      "    Hist Gradient Boosting: 0.6441\n",
      "    Linear Regression: 0.5144\n",
      "    Ridge Regression: 0.5144\n",
      "    Lasso Regression: 0.5144\n",
      "    ElasticNet Regression: 0.5144\n",
      "    Support Vector Regressor: 0.0208\n",
      "    K-Neighbors Regressor: 0.5650\n",
      "    Decision Tree Regressor: 0.5930\n",
      "    AdaBoost Regressor: 0.5382\n",
      "    LightGBM Regressor: 0.6648\n",
      "    XGBoost Regressor: 0.6938\n",
      "  Target: career_revives\n",
      "    Random Forest: 0.6170\n",
      "    Extra Trees Regressor: 0.6326\n",
      "    Gradient Boosting: 0.4689\n",
      "    Hist Gradient Boosting: 0.4486\n",
      "    Linear Regression: 0.3018\n",
      "    Ridge Regression: 0.3018\n",
      "    Lasso Regression: 0.3018\n",
      "    ElasticNet Regression: 0.3018\n",
      "    Support Vector Regressor: -0.0314\n",
      "    K-Neighbors Regressor: 0.3574\n",
      "    Decision Tree Regressor: 0.4091\n",
      "    AdaBoost Regressor: -0.2015\n",
      "    LightGBM Regressor: 0.4678\n",
      "    XGBoost Regressor: 0.5599\n",
      "\n",
      "Results for KNN Imputation:\n",
      "  Target: career_kills\n",
      "    Random Forest: 0.5991\n",
      "    Extra Trees Regressor: 0.5561\n",
      "    Gradient Boosting: 0.6219\n",
      "    Hist Gradient Boosting: 0.6501\n",
      "    Linear Regression: 0.6461\n",
      "    Ridge Regression: 0.6461\n",
      "    Lasso Regression: 0.6461\n",
      "    ElasticNet Regression: 0.6461\n",
      "    Support Vector Regressor: -0.0871\n",
      "    K-Neighbors Regressor: 0.6234\n",
      "    Decision Tree Regressor: 0.0614\n",
      "    AdaBoost Regressor: 0.5076\n",
      "    LightGBM Regressor: 0.6431\n",
      "    XGBoost Regressor: 0.4500\n",
      "  Target: career_wins\n",
      "    Random Forest: 0.6535\n",
      "    Extra Trees Regressor: 0.6577\n",
      "    Gradient Boosting: 0.6561\n",
      "    Hist Gradient Boosting: 0.6675\n",
      "    Linear Regression: 0.5965\n",
      "    Ridge Regression: 0.5965\n",
      "    Lasso Regression: 0.5965\n",
      "    ElasticNet Regression: 0.5965\n",
      "    Support Vector Regressor: 0.0499\n",
      "    K-Neighbors Regressor: 0.6552\n",
      "    Decision Tree Regressor: 0.4133\n",
      "    AdaBoost Regressor: 0.6123\n",
      "    LightGBM Regressor: 0.6593\n",
      "    XGBoost Regressor: 0.6134\n",
      "  Target: career_revives\n",
      "    Random Forest: 0.3585\n",
      "    Extra Trees Regressor: 0.3242\n",
      "    Gradient Boosting: 0.3101\n",
      "    Hist Gradient Boosting: 0.3193\n",
      "    Linear Regression: 0.3172\n",
      "    Ridge Regression: 0.3172\n",
      "    Lasso Regression: 0.3172\n",
      "    ElasticNet Regression: 0.3172\n",
      "    Support Vector Regressor: -0.0315\n",
      "    K-Neighbors Regressor: 0.3576\n",
      "    Decision Tree Regressor: 0.1527\n",
      "    AdaBoost Regressor: -0.3488\n",
      "    LightGBM Regressor: 0.3120\n",
      "    XGBoost Regressor: 0.2258\n",
      "\n",
      "Results for Mean Imputation:\n",
      "  Target: career_kills\n",
      "    Random Forest: 0.1493\n",
      "    Extra Trees Regressor: 0.0882\n",
      "    Gradient Boosting: 0.1871\n",
      "    Hist Gradient Boosting: 0.1785\n",
      "    Linear Regression: 0.2368\n",
      "    Ridge Regression: 0.2368\n",
      "    Lasso Regression: 0.2368\n",
      "    ElasticNet Regression: 0.2368\n",
      "    Support Vector Regressor: -0.0957\n",
      "    K-Neighbors Regressor: -0.0847\n",
      "    Decision Tree Regressor: -0.0250\n",
      "    AdaBoost Regressor: 0.1929\n",
      "    LightGBM Regressor: 0.1765\n",
      "    XGBoost Regressor: 0.0999\n",
      "  Target: career_wins\n",
      "    Random Forest: 0.1082\n",
      "    Extra Trees Regressor: -0.0324\n",
      "    Gradient Boosting: 0.2331\n",
      "    Hist Gradient Boosting: 0.2295\n",
      "    Linear Regression: 0.2356\n",
      "    Ridge Regression: 0.2356\n",
      "    Lasso Regression: 0.2356\n",
      "    ElasticNet Regression: 0.2356\n",
      "    Support Vector Regressor: 0.0019\n",
      "    K-Neighbors Regressor: 0.1818\n",
      "    Decision Tree Regressor: -0.2886\n",
      "    AdaBoost Regressor: 0.2103\n",
      "    LightGBM Regressor: 0.2568\n",
      "    XGBoost Regressor: 0.0680\n",
      "  Target: career_revives\n",
      "    Random Forest: -0.3990\n",
      "    Extra Trees Regressor: -0.5280\n",
      "    Gradient Boosting: -0.1670\n",
      "    Hist Gradient Boosting: -0.2170\n",
      "    Linear Regression: -0.0002\n",
      "    Ridge Regression: -0.0002\n",
      "    Lasso Regression: -0.0002\n",
      "    ElasticNet Regression: -0.0002\n",
      "    Support Vector Regressor: -0.0009\n",
      "    K-Neighbors Regressor: -0.2496\n",
      "    Decision Tree Regressor: -1.4622\n",
      "    AdaBoost Regressor: -1.1508\n",
      "    LightGBM Regressor: -0.1908\n",
      "    XGBoost Regressor: -0.5323\n",
      "\n",
      "Results for Median Imputation:\n",
      "  Target: career_kills\n",
      "    Random Forest: 0.1514\n",
      "    Extra Trees Regressor: 0.0915\n",
      "    Gradient Boosting: 0.1864\n",
      "    Hist Gradient Boosting: 0.1621\n",
      "    Linear Regression: 0.2293\n",
      "    Ridge Regression: 0.2293\n",
      "    Lasso Regression: 0.2293\n",
      "    ElasticNet Regression: 0.2293\n",
      "    Support Vector Regressor: -0.0941\n",
      "    K-Neighbors Regressor: 0.1408\n",
      "    Decision Tree Regressor: -0.0025\n",
      "    AdaBoost Regressor: 0.2371\n",
      "    LightGBM Regressor: 0.1728\n",
      "    XGBoost Regressor: 0.0663\n",
      "  Target: career_wins\n",
      "    Random Forest: 0.1312\n",
      "    Extra Trees Regressor: -0.0483\n",
      "    Gradient Boosting: 0.2226\n",
      "    Hist Gradient Boosting: 0.2326\n",
      "    Linear Regression: 0.2360\n",
      "    Ridge Regression: 0.2360\n",
      "    Lasso Regression: 0.2360\n",
      "    ElasticNet Regression: 0.2360\n",
      "    Support Vector Regressor: -0.0098\n",
      "    K-Neighbors Regressor: 0.1418\n",
      "    Decision Tree Regressor: -0.2699\n",
      "    AdaBoost Regressor: 0.1447\n",
      "    LightGBM Regressor: 0.2698\n",
      "    XGBoost Regressor: 0.0581\n",
      "  Target: career_revives\n",
      "    Random Forest: -0.3788\n",
      "    Extra Trees Regressor: -0.4821\n",
      "    Gradient Boosting: -0.1672\n",
      "    Hist Gradient Boosting: -0.2391\n",
      "    Linear Regression: -0.0112\n",
      "    Ridge Regression: -0.0112\n",
      "    Lasso Regression: -0.0112\n",
      "    ElasticNet Regression: -0.0112\n",
      "    Support Vector Regressor: -0.0305\n",
      "    K-Neighbors Regressor: -0.2601\n",
      "    Decision Tree Regressor: -1.1288\n",
      "    AdaBoost Regressor: -2.0296\n",
      "    LightGBM Regressor: -0.1824\n",
      "    XGBoost Regressor: -0.5310\n",
      "\n",
      "Results for XGBoost Imputation:\n",
      "  Target: career_kills\n",
      "    Random Forest: 0.5835\n",
      "    Extra Trees Regressor: 0.5590\n",
      "    Gradient Boosting: 0.6074\n",
      "    Hist Gradient Boosting: 0.5263\n",
      "    Linear Regression: 0.5495\n",
      "    Ridge Regression: 0.5495\n",
      "    Lasso Regression: 0.5495\n",
      "    ElasticNet Regression: 0.5495\n",
      "    Support Vector Regressor: -0.1099\n",
      "    K-Neighbors Regressor: 0.5575\n",
      "    Decision Tree Regressor: 0.2395\n",
      "    AdaBoost Regressor: 0.4558\n",
      "    LightGBM Regressor: 0.5267\n",
      "    XGBoost Regressor: 0.3938\n",
      "  Target: career_wins\n",
      "    Random Forest: 0.7355\n",
      "    Extra Trees Regressor: 0.7225\n",
      "    Gradient Boosting: 0.7011\n",
      "    Hist Gradient Boosting: 0.7097\n",
      "    Linear Regression: 0.6248\n",
      "    Ridge Regression: 0.6248\n",
      "    Lasso Regression: 0.6248\n",
      "    ElasticNet Regression: 0.6248\n",
      "    Support Vector Regressor: 0.0354\n",
      "    K-Neighbors Regressor: 0.6805\n",
      "    Decision Tree Regressor: 0.5955\n",
      "    AdaBoost Regressor: 0.6492\n",
      "    LightGBM Regressor: 0.7113\n",
      "    XGBoost Regressor: 0.6899\n",
      "  Target: career_revives\n",
      "    Random Forest: 0.6074\n",
      "    Extra Trees Regressor: 0.5955\n",
      "    Gradient Boosting: 0.5640\n",
      "    Hist Gradient Boosting: 0.5692\n",
      "    Linear Regression: 0.4201\n",
      "    Ridge Regression: 0.4201\n",
      "    Lasso Regression: 0.4201\n",
      "    ElasticNet Regression: 0.4201\n",
      "    Support Vector Regressor: -0.0388\n",
      "    K-Neighbors Regressor: 0.4195\n",
      "    Decision Tree Regressor: 0.4167\n",
      "    AdaBoost Regressor: 0.0525\n",
      "    LightGBM Regressor: 0.5946\n",
      "    XGBoost Regressor: 0.4238\n",
      "\n",
      "Results for MICE Imputation:\n",
      "  Target: career_kills\n",
      "    Random Forest: 0.5752\n",
      "    Extra Trees Regressor: 0.6016\n",
      "    Gradient Boosting: 0.6344\n",
      "    Hist Gradient Boosting: 0.6300\n",
      "    Linear Regression: 0.6356\n",
      "    Ridge Regression: 0.6356\n",
      "    Lasso Regression: 0.6356\n",
      "    ElasticNet Regression: 0.6356\n",
      "    Support Vector Regressor: -0.0880\n",
      "    K-Neighbors Regressor: 0.6511\n",
      "    Decision Tree Regressor: 0.1267\n",
      "    AdaBoost Regressor: 0.5202\n",
      "    LightGBM Regressor: 0.6141\n",
      "    XGBoost Regressor: 0.5352\n",
      "  Target: career_wins\n",
      "    Random Forest: 0.6259\n",
      "    Extra Trees Regressor: 0.6218\n",
      "    Gradient Boosting: 0.6684\n",
      "    Hist Gradient Boosting: 0.6390\n",
      "    Linear Regression: 0.6521\n",
      "    Ridge Regression: 0.6521\n",
      "    Lasso Regression: 0.6521\n",
      "    ElasticNet Regression: 0.6521\n",
      "    Support Vector Regressor: 0.0478\n",
      "    K-Neighbors Regressor: 0.6387\n",
      "    Decision Tree Regressor: 0.3841\n",
      "    AdaBoost Regressor: 0.6166\n",
      "    LightGBM Regressor: 0.6458\n",
      "    XGBoost Regressor: 0.5816\n",
      "  Target: career_revives\n",
      "    Random Forest: 0.2746\n",
      "    Extra Trees Regressor: 0.2335\n",
      "    Gradient Boosting: 0.2963\n",
      "    Hist Gradient Boosting: 0.2511\n",
      "    Linear Regression: 0.3915\n",
      "    Ridge Regression: 0.3915\n",
      "    Lasso Regression: 0.3915\n",
      "    ElasticNet Regression: 0.3915\n",
      "    Support Vector Regressor: -0.0197\n",
      "    K-Neighbors Regressor: 0.2105\n",
      "    Decision Tree Regressor: -0.4637\n",
      "    AdaBoost Regressor: -0.4800\n",
      "    LightGBM Regressor: 0.2727\n",
      "    XGBoost Regressor: 0.0218\n",
      "\n",
      "Best Combinations:\n",
      "career_kills: Logistic Regression Imputation with Random Forest (Score: 0.8951)\n",
      "career_wins: XGBoost Imputation with Random Forest (Score: 0.7355)\n",
      "career_revives: Random Forest Imputation with Extra Trees Regressor (Score: 0.6326)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the regression models to be used\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "    \"Extra Trees Regressor\": ExtraTreesRegressor(),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(),\n",
    "    \"Hist Gradient Boosting\": HistGradientBoostingRegressor(),\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(),\n",
    "    \"Lasso Regression\": Lasso(),\n",
    "    \"ElasticNet Regression\": ElasticNet(),\n",
    "    \"Support Vector Regressor\": SVR(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Decision Tree Regressor\": DecisionTreeRegressor(),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor(),\n",
    "    \"LightGBM Regressor\": lgb.LGBMRegressor(),\n",
    "    \"XGBoost Regressor\": XGBRegressor()\n",
    "}\n",
    "\n",
    "# Function to fit and score models\n",
    "def fit_and_score(models, X_train, X_test, y_train, y_test):\n",
    "    np.random.seed(42)\n",
    "    model_scores = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        model_scores[name] = model.score(X_test, y_test)\n",
    "    return model_scores\n",
    "\n",
    "# Function to run model prediction\n",
    "def run_model_prediction(target_column, df):\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    model_scores = fit_and_score(models=models, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n",
    "    return model_scores\n",
    "\n",
    "# Target columns to predict\n",
    "target_columns = ['career_kills', 'career_wins', 'career_revives']\n",
    "\n",
    "# Dictionary to store results for each imputation method and each target column\n",
    "all_results = {}\n",
    "\n",
    "# Running models on each imputed dataset for each target column\n",
    "for imputation_method, imputed_df in imputed_dataframes.items():\n",
    "    print(f\"\\nRunning models on {imputation_method} data:\")\n",
    "    # Drop the player_name column\n",
    "    imputed_df = imputed_df.drop(columns=['player_name'])\n",
    "    \n",
    "    imputation_results = {}\n",
    "    for target_column in target_columns:\n",
    "        print(f\"  Predicting {target_column}...\")\n",
    "        model_scores = run_model_prediction(target_column, imputed_df)\n",
    "        imputation_results[target_column] = model_scores\n",
    "    all_results[imputation_method] = imputation_results\n",
    "\n",
    "# Results\n",
    "for imputation_method, imputation_results in all_results.items():\n",
    "    print(f\"\\nResults for {imputation_method}:\")\n",
    "    for target_column, model_scores in imputation_results.items():\n",
    "        print(f\"  Target: {target_column}\")\n",
    "        for model_name, score in model_scores.items():\n",
    "            print(f\"    {model_name}: {score:.4f}\")\n",
    "\n",
    "# Find the best model and imputation method for each target\n",
    "best_combinations = {}\n",
    "for target_column in target_columns:\n",
    "    best_score = float('-inf')  # Initialize to the lowest possible score\n",
    "    best_model = \"\"\n",
    "    best_imputation = \"\"\n",
    "    for imputation_method, imputation_results in all_results.items():\n",
    "        for model_name, score in imputation_results[target_column].items():\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_model = model_name\n",
    "                best_imputation = imputation_method\n",
    "    best_combinations[target_column] = (best_imputation, best_model, best_score)\n",
    "\n",
    "print(\"\\nBest Combinations:\")\n",
    "for target, (imputation, model, score) in best_combinations.items():\n",
    "    print(f\"{target}: {imputation} with {model} (Score: {score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Career Kills Distribution:\n",
      "count      1904.000000\n",
      "mean      96842.709559\n",
      "std       29643.591753\n",
      "min        5374.000000\n",
      "25%       78829.000000\n",
      "50%       89994.000000\n",
      "75%      107428.000000\n",
      "max      371099.000000\n",
      "Name: career_kills, dtype: float64\n",
      "\n",
      "Career Wins Distribution:\n",
      "count      973.00000\n",
      "mean      6507.21480\n",
      "std       2563.48393\n",
      "min         52.00000\n",
      "25%       4721.00000\n",
      "50%       6099.00000\n",
      "75%       7716.00000\n",
      "max      21010.00000\n",
      "Name: career_wins, dtype: float64\n",
      "\n",
      "Career Revives Distribution:\n",
      "count      896.000000\n",
      "mean     13735.802455\n",
      "std       5901.073875\n",
      "min       3288.000000\n",
      "25%      10250.000000\n",
      "50%      12159.500000\n",
      "75%      15508.250000\n",
      "max      67615.000000\n",
      "Name: career_revives, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Career Kills Distribution:\")\n",
    "print(Career_Stats_df['career_kills'].describe())\n",
    "print(\"\\nCareer Wins Distribution:\")\n",
    "print(Career_Stats_df['career_wins'].describe())\n",
    "print(\"\\nCareer Revives Distribution:\")\n",
    "print(Career_Stats_df['career_revives'].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Existing Imputation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning KNN Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Tune the number of neighbors\n",
    "knn_imputer_5 = KNNImputer(n_neighbors=5)\n",
    "df_knn_imputed_5 = pd.DataFrame(knn_imputer_5.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "df_knn_imputed_5.insert(0, 'player_name', player_names)\n",
    "\n",
    "knn_imputer_10 = KNNImputer(n_neighbors=10)\n",
    "df_knn_imputed_10 = pd.DataFrame(knn_imputer_10.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "df_knn_imputed_10.insert(0, 'player_name', player_names)\n",
    "\n",
    "knn_imputer_15 = KNNImputer(n_neighbors=15)\n",
    "df_knn_imputed_15 = pd.DataFrame(knn_imputer_15.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "df_knn_imputed_15.insert(0, 'player_name', player_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning-Based Imputation\n",
    "Using Autoencoders for Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "# Define an autoencoder model\n",
    "def build_autoencoder(input_dim):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoded = Dense(64, activation='relu')(input_layer)\n",
    "    encoded = Dense(32, activation='relu')(encoded)\n",
    "    encoded = Dense(16, activation='relu')(encoded)\n",
    "    decoded = Dense(32, activation='relu')(encoded)\n",
    "    decoded = Dense(64, activation='relu')(decoded)\n",
    "    output_layer = Dense(input_dim, activation='linear')(decoded)\n",
    "    autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "    autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return autoencoder\n",
    "\n",
    "# Prepare the data for the autoencoder\n",
    "numeric_df_imputed = numeric_df.fillna(numeric_df.mean())  # Initial imputation to handle NaNs\n",
    "X_train_ae = numeric_df_imputed.values\n",
    "\n",
    "# Build and train the autoencoder\n",
    "input_dim = X_train_ae.shape[1]\n",
    "autoencoder = build_autoencoder(input_dim)\n",
    "autoencoder.fit(X_train_ae, X_train_ae, epochs=100, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Use the trained autoencoder to fill missing values\n",
    "encoded_data = autoencoder.predict(X_train_ae)\n",
    "df_autoencoder_imputed = pd.DataFrame(encoded_data, columns=numeric_df.columns)\n",
    "df_autoencoder_imputed.insert(0, 'player_name', player_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation for Imputation Evaluation\n",
    "Cross-Validation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validating Mode Imputation data...\n",
      "  Predicting career_kills...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96214.240539\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96511.686337\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 95176.742784\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96124.139833\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96422.282051\n",
      "  Predicting career_wins...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 5775.511225\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 5751.362412\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 5688.320077\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 5743.567030\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 5700.838462\n",
      "  Predicting career_revives...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 12001.595253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 11962.834509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 11761.549711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 11920.665811\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 11848.223077\n",
      "\n",
      "Cross-validating Logistic Regression Imputation data...\n",
      "  Predicting career_kills...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96380.227710\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96687.437460\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 95347.611931\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96295.008980\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96617.435897\n",
      "  Predicting career_wins...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 8665.666453\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 8595.910199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 8511.548428\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 8603.502886\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 8558.849359\n",
      "  Predicting career_revives...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 18440.438101\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 18685.110969\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 18577.923669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 18525.699808\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 18568.902564\n",
      "\n",
      "Cross-validating Random Forest Imputation data...\n",
      "  Predicting career_kills...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 507\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 97171.322001\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 507\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 97525.066709\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 506\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96161.973701\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000032 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 504\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 97109.370750\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 509\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 97547.538462\n",
      "  Predicting career_wins...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 508\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6327.481078\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 508\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6339.376523\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 507\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6268.784477\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000033 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 505\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6309.161642\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 509\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6282.348077\n",
      "  Predicting career_revives...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 509\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13506.892239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 509\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13553.379731\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 509\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13244.774856\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 509\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13455.500962\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000032 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13432.596154\n",
      "\n",
      "Cross-validating KNN Imputation (5 neighbors) data...\n",
      "  Predicting career_kills...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96925.355466\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 97264.631555\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 95908.772856\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96856.169906\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 97258.351562\n",
      "  Predicting career_wins...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6431.060623\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6443.516574\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6356.702837\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6418.099377\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6398.477563\n",
      "  Predicting career_revives...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13843.317442\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13852.801602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13646.477162\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13869.654582\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13787.024558\n",
      "\n",
      "Cross-validating KNN Imputation (10 neighbors) data...\n",
      "  Predicting career_kills...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96925.355466\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 97264.631555\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 95908.772856\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96856.169906\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 97258.351562\n",
      "  Predicting career_wins...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6445.396675\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6450.088228\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6363.397775\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6423.943767\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6412.687635\n",
      "  Predicting career_revives...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13850.425972\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13851.427640\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13614.737069\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13803.397747\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13761.008018\n",
      "\n",
      "Cross-validating KNN Imputation (15 neighbors) data...\n",
      "  Predicting career_kills...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96925.355466\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 97264.631555\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 95908.772856\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96856.169906\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 97258.351562\n",
      "  Predicting career_wins...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6442.101249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6443.243878\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6354.335724\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6417.048189\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6407.934528\n",
      "  Predicting career_revives...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13821.252139\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13833.953614\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13603.536253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13782.196937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13728.073225\n",
      "\n",
      "Cross-validating Mean Imputation data...\n",
      "  Predicting career_kills...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96925.355466\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 97264.631555\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 95908.772856\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96856.169906\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 97258.351562\n",
      "  Predicting career_wins...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6543.163614\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6521.994047\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6468.882532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6514.198665\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6487.847674\n",
      "  Predicting career_revives...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13805.082656\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13794.671775\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13619.556081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13756.864594\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13702.859056\n",
      "\n",
      "Cross-validating Median Imputation data...\n",
      "  Predicting career_kills...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96775.992944\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 97106.483002\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 95755.017319\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96702.414368\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 97082.743590\n",
      "  Predicting career_wins...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6340.758178\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6318.803079\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6263.073124\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6311.007697\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6280.338462\n",
      "  Predicting career_revives...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000063 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 12968.904105\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 12945.348942\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 12758.100064\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 12905.519564\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 12842.965705\n",
      "\n",
      "Cross-validating XGBoost Imputation data...\n",
      "  Predicting career_kills...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96738.681406\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000060 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 97066.976668\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 95716.608383\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96664.005432\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 97038.875801\n",
      "  Predicting career_wins...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6489.552431\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6482.500041\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6410.345108\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6460.953138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6461.507410\n",
      "  Predicting career_revives...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 14017.943667\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13965.698377\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13821.531870\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13931.023945\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13923.592033\n",
      "\n",
      "Cross-validating MICE Imputation data...\n",
      "  Predicting career_kills...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96925.355466\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 97264.631555\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 95908.772856\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96856.169906\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 97258.351562\n",
      "  Predicting career_wins...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6435.737154\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6432.779325\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6343.732288\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6412.086263\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6389.532633\n",
      "  Predicting career_revives...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13877.275230\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13882.513967\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13655.225776\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13820.860802\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13746.713862\n",
      "\n",
      "Cross-validating Autoencoder Imputation data...\n",
      "  Predicting career_kills...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96962.192834\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 97300.774768\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 95944.938177\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 96892.659089\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 97294.255947\n",
      "  Predicting career_wins...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6452.086029\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6430.909739\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6378.748031\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6423.184998\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 6396.513541\n",
      "  Predicting career_revives...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13656.619229\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13646.979895\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13473.112548\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1559, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13609.029034\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1560, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 13555.523479\n",
      "\n",
      "Cross-validation results for Mode Imputation:\n",
      "  Target: career_kills\n",
      "    Random Forest: 0.2554\n",
      "    Extra Trees Regressor: 0.1909\n",
      "    Gradient Boosting: 0.2751\n",
      "    Hist Gradient Boosting: 0.2962\n",
      "    Linear Regression: 0.3069\n",
      "    Ridge Regression: 0.3069\n",
      "    Lasso Regression: 0.3069\n",
      "    ElasticNet Regression: 0.3069\n",
      "    Support Vector Regressor: -0.0516\n",
      "    K-Neighbors Regressor: -4.1306\n",
      "    Decision Tree Regressor: 0.0154\n",
      "    AdaBoost Regressor: 0.1629\n",
      "    LightGBM Regressor: 0.2967\n",
      "    XGBoost Regressor: 0.2080\n",
      "  Target: career_wins\n",
      "    Random Forest: 0.1654\n",
      "    Extra Trees Regressor: 0.0933\n",
      "    Gradient Boosting: 0.3134\n",
      "    Hist Gradient Boosting: 0.3266\n",
      "    Linear Regression: 0.3737\n",
      "    Ridge Regression: 0.3737\n",
      "    Lasso Regression: 0.3737\n",
      "    ElasticNet Regression: 0.3737\n",
      "    Support Vector Regressor: -0.1514\n",
      "    K-Neighbors Regressor: 0.2458\n",
      "    Decision Tree Regressor: -0.3416\n",
      "    AdaBoost Regressor: 0.2492\n",
      "    LightGBM Regressor: 0.3133\n",
      "    XGBoost Regressor: 0.2152\n",
      "  Target: career_revives\n",
      "    Random Forest: -0.0571\n",
      "    Extra Trees Regressor: -0.1657\n",
      "    Gradient Boosting: 0.0793\n",
      "    Hist Gradient Boosting: 0.0661\n",
      "    Linear Regression: 0.1850\n",
      "    Ridge Regression: 0.1850\n",
      "    Lasso Regression: 0.1850\n",
      "    ElasticNet Regression: 0.1850\n",
      "    Support Vector Regressor: -0.1367\n",
      "    K-Neighbors Regressor: -0.0080\n",
      "    Decision Tree Regressor: -0.6129\n",
      "    AdaBoost Regressor: -1.1384\n",
      "    LightGBM Regressor: 0.0619\n",
      "    XGBoost Regressor: -0.2229\n",
      "\n",
      "Cross-validation results for Logistic Regression Imputation:\n",
      "  Target: career_kills\n",
      "    Random Forest: 0.6088\n",
      "    Extra Trees Regressor: 0.5799\n",
      "    Gradient Boosting: 0.5499\n",
      "    Hist Gradient Boosting: 0.5986\n",
      "    Linear Regression: 0.1231\n",
      "    Ridge Regression: 0.1231\n",
      "    Lasso Regression: 0.1231\n",
      "    ElasticNet Regression: 0.1231\n",
      "    Support Vector Regressor: -0.0552\n",
      "    K-Neighbors Regressor: 0.4632\n",
      "    Decision Tree Regressor: 0.2895\n",
      "    AdaBoost Regressor: -0.1609\n",
      "    LightGBM Regressor: 0.5894\n",
      "    XGBoost Regressor: 0.5927\n",
      "  Target: career_wins\n",
      "    Random Forest: 0.6485\n",
      "    Extra Trees Regressor: 0.6612\n",
      "    Gradient Boosting: 0.6263\n",
      "    Hist Gradient Boosting: 0.6385\n",
      "    Linear Regression: 0.1254\n",
      "    Ridge Regression: 0.1254\n",
      "    Lasso Regression: 0.1254\n",
      "    ElasticNet Regression: 0.1254\n",
      "    Support Vector Regressor: -0.1066\n",
      "    K-Neighbors Regressor: 0.4774\n",
      "    Decision Tree Regressor: 0.4074\n",
      "    AdaBoost Regressor: 0.2359\n",
      "    LightGBM Regressor: 0.6507\n",
      "    XGBoost Regressor: 0.6211\n",
      "  Target: career_revives\n",
      "    Random Forest: 0.4544\n",
      "    Extra Trees Regressor: 0.4590\n",
      "    Gradient Boosting: 0.3634\n",
      "    Hist Gradient Boosting: 0.4427\n",
      "    Linear Regression: 0.0148\n",
      "    Ridge Regression: 0.0148\n",
      "    Lasso Regression: 0.0148\n",
      "    ElasticNet Regression: 0.0148\n",
      "    Support Vector Regressor: -0.2375\n",
      "    K-Neighbors Regressor: 0.3482\n",
      "    Decision Tree Regressor: 0.1126\n",
      "    AdaBoost Regressor: 0.0230\n",
      "    LightGBM Regressor: 0.4409\n",
      "    XGBoost Regressor: 0.3847\n",
      "\n",
      "Cross-validation results for Random Forest Imputation:\n",
      "  Target: career_kills\n",
      "    Random Forest: 0.7798\n",
      "    Extra Trees Regressor: 0.8098\n",
      "    Gradient Boosting: 0.6802\n",
      "    Hist Gradient Boosting: 0.6686\n",
      "    Linear Regression: 0.5340\n",
      "    Ridge Regression: 0.5340\n",
      "    Lasso Regression: 0.5340\n",
      "    ElasticNet Regression: 0.5340\n",
      "    Support Vector Regressor: -0.0487\n",
      "    K-Neighbors Regressor: 0.6157\n",
      "    Decision Tree Regressor: 0.7082\n",
      "    AdaBoost Regressor: 0.5271\n",
      "    LightGBM Regressor: 0.6696\n",
      "    XGBoost Regressor: 0.7641\n",
      "  Target: career_wins\n",
      "    Random Forest: 0.7776\n",
      "    Extra Trees Regressor: 0.8009\n",
      "    Gradient Boosting: 0.6937\n",
      "    Hist Gradient Boosting: 0.7306\n",
      "    Linear Regression: 0.5727\n",
      "    Ridge Regression: 0.5727\n",
      "    Lasso Regression: 0.5727\n",
      "    ElasticNet Regression: 0.5727\n",
      "    Support Vector Regressor: 0.0458\n",
      "    K-Neighbors Regressor: 0.6828\n",
      "    Decision Tree Regressor: 0.6360\n",
      "    AdaBoost Regressor: 0.5761\n",
      "    LightGBM Regressor: 0.7291\n",
      "    XGBoost Regressor: 0.7588\n",
      "  Target: career_revives\n",
      "    Random Forest: 0.6530\n",
      "    Extra Trees Regressor: 0.6798\n",
      "    Gradient Boosting: 0.5319\n",
      "    Hist Gradient Boosting: 0.5447\n",
      "    Linear Regression: 0.2762\n",
      "    Ridge Regression: 0.2762\n",
      "    Lasso Regression: 0.2762\n",
      "    ElasticNet Regression: 0.2762\n",
      "    Support Vector Regressor: -0.0600\n",
      "    K-Neighbors Regressor: 0.4671\n",
      "    Decision Tree Regressor: 0.5188\n",
      "    AdaBoost Regressor: -0.0350\n",
      "    LightGBM Regressor: 0.5619\n",
      "    XGBoost Regressor: 0.6532\n",
      "\n",
      "Cross-validation results for KNN Imputation (5 neighbors):\n",
      "  Target: career_kills\n",
      "    Random Forest: 0.6356\n",
      "    Extra Trees Regressor: 0.6222\n",
      "    Gradient Boosting: 0.6600\n",
      "    Hist Gradient Boosting: 0.6595\n",
      "    Linear Regression: 0.6559\n",
      "    Ridge Regression: 0.6559\n",
      "    Lasso Regression: 0.6559\n",
      "    ElasticNet Regression: 0.6559\n",
      "    Support Vector Regressor: -0.0426\n",
      "    K-Neighbors Regressor: 0.6304\n",
      "    Decision Tree Regressor: 0.4001\n",
      "    AdaBoost Regressor: 0.4685\n",
      "    LightGBM Regressor: 0.6591\n",
      "    XGBoost Regressor: 0.5936\n",
      "  Target: career_wins\n",
      "    Random Forest: 0.6782\n",
      "    Extra Trees Regressor: 0.6727\n",
      "    Gradient Boosting: 0.6881\n",
      "    Hist Gradient Boosting: 0.6714\n",
      "    Linear Regression: 0.6452\n",
      "    Ridge Regression: 0.6452\n",
      "    Lasso Regression: 0.6452\n",
      "    ElasticNet Regression: 0.6452\n",
      "    Support Vector Regressor: 0.0659\n",
      "    K-Neighbors Regressor: 0.6629\n",
      "    Decision Tree Regressor: 0.4648\n",
      "    AdaBoost Regressor: 0.6039\n",
      "    LightGBM Regressor: 0.6766\n",
      "    XGBoost Regressor: 0.6628\n",
      "  Target: career_revives\n",
      "    Random Forest: 0.4380\n",
      "    Extra Trees Regressor: 0.3723\n",
      "    Gradient Boosting: 0.4403\n",
      "    Hist Gradient Boosting: 0.4350\n",
      "    Linear Regression: 0.4080\n",
      "    Ridge Regression: 0.4080\n",
      "    Lasso Regression: 0.4080\n",
      "    ElasticNet Regression: 0.4080\n",
      "    Support Vector Regressor: -0.0379\n",
      "    K-Neighbors Regressor: 0.4126\n",
      "    Decision Tree Regressor: 0.1102\n",
      "    AdaBoost Regressor: -0.1112\n",
      "    LightGBM Regressor: 0.4254\n",
      "    XGBoost Regressor: 0.3151\n",
      "\n",
      "Cross-validation results for KNN Imputation (10 neighbors):\n",
      "  Target: career_kills\n",
      "    Random Forest: 0.6605\n",
      "    Extra Trees Regressor: 0.6514\n",
      "    Gradient Boosting: 0.6780\n",
      "    Hist Gradient Boosting: 0.6800\n",
      "    Linear Regression: 0.6669\n",
      "    Ridge Regression: 0.6669\n",
      "    Lasso Regression: 0.6669\n",
      "    ElasticNet Regression: 0.6669\n",
      "    Support Vector Regressor: -0.0418\n",
      "    K-Neighbors Regressor: 0.6414\n",
      "    Decision Tree Regressor: 0.4345\n",
      "    AdaBoost Regressor: 0.5024\n",
      "    LightGBM Regressor: 0.6809\n",
      "    XGBoost Regressor: 0.5982\n",
      "  Target: career_wins\n",
      "    Random Forest: 0.6662\n",
      "    Extra Trees Regressor: 0.6591\n",
      "    Gradient Boosting: 0.6852\n",
      "    Hist Gradient Boosting: 0.6770\n",
      "    Linear Regression: 0.6632\n",
      "    Ridge Regression: 0.6632\n",
      "    Lasso Regression: 0.6632\n",
      "    ElasticNet Regression: 0.6632\n",
      "    Support Vector Regressor: 0.0714\n",
      "    K-Neighbors Regressor: 0.6748\n",
      "    Decision Tree Regressor: 0.4574\n",
      "    AdaBoost Regressor: 0.5887\n",
      "    LightGBM Regressor: 0.6787\n",
      "    XGBoost Regressor: 0.6341\n",
      "  Target: career_revives\n",
      "    Random Forest: 0.3764\n",
      "    Extra Trees Regressor: 0.3118\n",
      "    Gradient Boosting: 0.4193\n",
      "    Hist Gradient Boosting: 0.4048\n",
      "    Linear Regression: 0.4294\n",
      "    Ridge Regression: 0.4294\n",
      "    Lasso Regression: 0.4294\n",
      "    ElasticNet Regression: 0.4294\n",
      "    Support Vector Regressor: -0.0203\n",
      "    K-Neighbors Regressor: 0.3812\n",
      "    Decision Tree Regressor: 0.0845\n",
      "    AdaBoost Regressor: -0.2323\n",
      "    LightGBM Regressor: 0.4178\n",
      "    XGBoost Regressor: 0.2598\n",
      "\n",
      "Cross-validation results for KNN Imputation (15 neighbors):\n",
      "  Target: career_kills\n",
      "    Random Forest: 0.6628\n",
      "    Extra Trees Regressor: 0.6488\n",
      "    Gradient Boosting: 0.6765\n",
      "    Hist Gradient Boosting: 0.7008\n",
      "    Linear Regression: 0.6669\n",
      "    Ridge Regression: 0.6669\n",
      "    Lasso Regression: 0.6669\n",
      "    ElasticNet Regression: 0.6669\n",
      "    Support Vector Regressor: -0.0415\n",
      "    K-Neighbors Regressor: 0.6450\n",
      "    Decision Tree Regressor: 0.4460\n",
      "    AdaBoost Regressor: 0.5392\n",
      "    LightGBM Regressor: 0.6984\n",
      "    XGBoost Regressor: 0.6256\n",
      "  Target: career_wins\n",
      "    Random Forest: 0.6536\n",
      "    Extra Trees Regressor: 0.6276\n",
      "    Gradient Boosting: 0.6782\n",
      "    Hist Gradient Boosting: 0.6685\n",
      "    Linear Regression: 0.6683\n",
      "    Ridge Regression: 0.6683\n",
      "    Lasso Regression: 0.6683\n",
      "    ElasticNet Regression: 0.6683\n",
      "    Support Vector Regressor: 0.0724\n",
      "    K-Neighbors Regressor: 0.6658\n",
      "    Decision Tree Regressor: 0.4236\n",
      "    AdaBoost Regressor: 0.6107\n",
      "    LightGBM Regressor: 0.6641\n",
      "    XGBoost Regressor: 0.5997\n",
      "  Target: career_revives\n",
      "    Random Forest: 0.3741\n",
      "    Extra Trees Regressor: 0.2997\n",
      "    Gradient Boosting: 0.3888\n",
      "    Hist Gradient Boosting: 0.3931\n",
      "    Linear Regression: 0.4323\n",
      "    Ridge Regression: 0.4323\n",
      "    Lasso Regression: 0.4323\n",
      "    ElasticNet Regression: 0.4323\n",
      "    Support Vector Regressor: -0.0267\n",
      "    K-Neighbors Regressor: 0.3533\n",
      "    Decision Tree Regressor: -0.0438\n",
      "    AdaBoost Regressor: -0.2417\n",
      "    LightGBM Regressor: 0.3882\n",
      "    XGBoost Regressor: 0.2391\n",
      "\n",
      "Cross-validation results for Mean Imputation:\n",
      "  Target: career_kills\n",
      "    Random Forest: 0.2552\n",
      "    Extra Trees Regressor: 0.1970\n",
      "    Gradient Boosting: 0.2780\n",
      "    Hist Gradient Boosting: 0.3020\n",
      "    Linear Regression: 0.3373\n",
      "    Ridge Regression: 0.3373\n",
      "    Lasso Regression: 0.3373\n",
      "    ElasticNet Regression: 0.3373\n",
      "    Support Vector Regressor: -0.0484\n",
      "    K-Neighbors Regressor: -6.3119\n",
      "    Decision Tree Regressor: 0.0054\n",
      "    AdaBoost Regressor: 0.2393\n",
      "    LightGBM Regressor: 0.3012\n",
      "    XGBoost Regressor: 0.2058\n",
      "  Target: career_wins\n",
      "    Random Forest: 0.1797\n",
      "    Extra Trees Regressor: 0.1101\n",
      "    Gradient Boosting: 0.3381\n",
      "    Hist Gradient Boosting: 0.3193\n",
      "    Linear Regression: 0.3739\n",
      "    Ridge Regression: 0.3739\n",
      "    Lasso Regression: 0.3739\n",
      "    ElasticNet Regression: 0.3739\n",
      "    Support Vector Regressor: -0.0011\n",
      "    K-Neighbors Regressor: 0.2391\n",
      "    Decision Tree Regressor: -0.2531\n",
      "    AdaBoost Regressor: 0.2431\n",
      "    LightGBM Regressor: 0.3070\n",
      "    XGBoost Regressor: 0.2116\n",
      "  Target: career_revives\n",
      "    Random Forest: -0.0993\n",
      "    Extra Trees Regressor: -0.2300\n",
      "    Gradient Boosting: 0.0649\n",
      "    Hist Gradient Boosting: 0.0403\n",
      "    Linear Regression: 0.1736\n",
      "    Ridge Regression: 0.1736\n",
      "    Lasso Regression: 0.1736\n",
      "    ElasticNet Regression: 0.1736\n",
      "    Support Vector Regressor: -0.0043\n",
      "    K-Neighbors Regressor: -0.0400\n",
      "    Decision Tree Regressor: -0.6073\n",
      "    AdaBoost Regressor: -0.8217\n",
      "    LightGBM Regressor: 0.0447\n",
      "    XGBoost Regressor: -0.1928\n",
      "\n",
      "Cross-validation results for Median Imputation:\n",
      "  Target: career_kills\n",
      "    Random Forest: 0.2562\n",
      "    Extra Trees Regressor: 0.1966\n",
      "    Gradient Boosting: 0.2808\n",
      "    Hist Gradient Boosting: 0.3014\n",
      "    Linear Regression: 0.3391\n",
      "    Ridge Regression: 0.3391\n",
      "    Lasso Regression: 0.3391\n",
      "    ElasticNet Regression: 0.3391\n",
      "    Support Vector Regressor: -0.0526\n",
      "    K-Neighbors Regressor: -6.1900\n",
      "    Decision Tree Regressor: 0.0156\n",
      "    AdaBoost Regressor: 0.1976\n",
      "    LightGBM Regressor: 0.2984\n",
      "    XGBoost Regressor: 0.2154\n",
      "  Target: career_wins\n",
      "    Random Forest: 0.1862\n",
      "    Extra Trees Regressor: 0.1086\n",
      "    Gradient Boosting: 0.3302\n",
      "    Hist Gradient Boosting: 0.3253\n",
      "    Linear Regression: 0.3785\n",
      "    Ridge Regression: 0.3785\n",
      "    Lasso Regression: 0.3785\n",
      "    ElasticNet Regression: 0.3785\n",
      "    Support Vector Regressor: -0.0118\n",
      "    K-Neighbors Regressor: 0.2537\n",
      "    Decision Tree Regressor: -0.2703\n",
      "    AdaBoost Regressor: 0.2478\n",
      "    LightGBM Regressor: 0.3161\n",
      "    XGBoost Regressor: 0.2141\n",
      "  Target: career_revives\n",
      "    Random Forest: -0.0745\n",
      "    Extra Trees Regressor: -0.2119\n",
      "    Gradient Boosting: 0.0641\n",
      "    Hist Gradient Boosting: 0.0447\n",
      "    Linear Regression: 0.1680\n",
      "    Ridge Regression: 0.1680\n",
      "    Lasso Regression: 0.1680\n",
      "    ElasticNet Regression: 0.1680\n",
      "    Support Vector Regressor: -0.0345\n",
      "    K-Neighbors Regressor: -0.0476\n",
      "    Decision Tree Regressor: -0.7493\n",
      "    AdaBoost Regressor: -0.8391\n",
      "    LightGBM Regressor: 0.0465\n",
      "    XGBoost Regressor: -0.2100\n",
      "\n",
      "Cross-validation results for XGBoost Imputation:\n",
      "  Target: career_kills\n",
      "    Random Forest: 0.6661\n",
      "    Extra Trees Regressor: 0.6619\n",
      "    Gradient Boosting: 0.6665\n",
      "    Hist Gradient Boosting: 0.5991\n",
      "    Linear Regression: 0.6011\n",
      "    Ridge Regression: 0.6011\n",
      "    Lasso Regression: 0.6011\n",
      "    ElasticNet Regression: 0.6011\n",
      "    Support Vector Regressor: -0.0574\n",
      "    K-Neighbors Regressor: 0.6114\n",
      "    Decision Tree Regressor: 0.4548\n",
      "    AdaBoost Regressor: 0.4864\n",
      "    LightGBM Regressor: 0.6029\n",
      "    XGBoost Regressor: 0.6311\n",
      "  Target: career_wins\n",
      "    Random Forest: 0.7159\n",
      "    Extra Trees Regressor: 0.7119\n",
      "    Gradient Boosting: 0.7120\n",
      "    Hist Gradient Boosting: 0.7138\n",
      "    Linear Regression: 0.6522\n",
      "    Ridge Regression: 0.6522\n",
      "    Lasso Regression: 0.6522\n",
      "    ElasticNet Regression: 0.6522\n",
      "    Support Vector Regressor: 0.0454\n",
      "    K-Neighbors Regressor: 0.6861\n",
      "    Decision Tree Regressor: 0.5622\n",
      "    AdaBoost Regressor: 0.6168\n",
      "    LightGBM Regressor: 0.7105\n",
      "    XGBoost Regressor: 0.6805\n",
      "  Target: career_revives\n",
      "    Random Forest: 0.5418\n",
      "    Extra Trees Regressor: 0.5207\n",
      "    Gradient Boosting: 0.5125\n",
      "    Hist Gradient Boosting: 0.5459\n",
      "    Linear Regression: 0.4371\n",
      "    Ridge Regression: 0.4371\n",
      "    Lasso Regression: 0.4371\n",
      "    ElasticNet Regression: 0.4371\n",
      "    Support Vector Regressor: -0.0466\n",
      "    K-Neighbors Regressor: 0.4533\n",
      "    Decision Tree Regressor: 0.1593\n",
      "    AdaBoost Regressor: 0.0107\n",
      "    LightGBM Regressor: 0.5671\n",
      "    XGBoost Regressor: 0.4645\n",
      "\n",
      "Cross-validation results for MICE Imputation:\n",
      "  Target: career_kills\n",
      "    Random Forest: 0.6710\n",
      "    Extra Trees Regressor: 0.6841\n",
      "    Gradient Boosting: 0.6958\n",
      "    Hist Gradient Boosting: 0.6764\n",
      "    Linear Regression: 0.6729\n",
      "    Ridge Regression: 0.6729\n",
      "    Lasso Regression: 0.6729\n",
      "    ElasticNet Regression: 0.6729\n",
      "    Support Vector Regressor: -0.0423\n",
      "    K-Neighbors Regressor: 0.6773\n",
      "    Decision Tree Regressor: 0.3342\n",
      "    AdaBoost Regressor: 0.5265\n",
      "    LightGBM Regressor: 0.6859\n",
      "    XGBoost Regressor: 0.6349\n",
      "  Target: career_wins\n",
      "    Random Forest: 0.6729\n",
      "    Extra Trees Regressor: 0.6671\n",
      "    Gradient Boosting: 0.7066\n",
      "    Hist Gradient Boosting: 0.6803\n",
      "    Linear Regression: 0.7099\n",
      "    Ridge Regression: 0.7099\n",
      "    Lasso Regression: 0.7099\n",
      "    ElasticNet Regression: 0.7099\n",
      "    Support Vector Regressor: 0.0633\n",
      "    K-Neighbors Regressor: 0.6736\n",
      "    Decision Tree Regressor: 0.4219\n",
      "    AdaBoost Regressor: 0.6197\n",
      "    LightGBM Regressor: 0.6703\n",
      "    XGBoost Regressor: 0.6267\n",
      "  Target: career_revives\n",
      "    Random Forest: 0.3990\n",
      "    Extra Trees Regressor: 0.3335\n",
      "    Gradient Boosting: 0.4429\n",
      "    Hist Gradient Boosting: 0.3978\n",
      "    Linear Regression: 0.4930\n",
      "    Ridge Regression: 0.4930\n",
      "    Lasso Regression: 0.4930\n",
      "    ElasticNet Regression: 0.4930\n",
      "    Support Vector Regressor: -0.0037\n",
      "    K-Neighbors Regressor: 0.3511\n",
      "    Decision Tree Regressor: 0.0547\n",
      "    AdaBoost Regressor: -0.1048\n",
      "    LightGBM Regressor: 0.3992\n",
      "    XGBoost Regressor: 0.2445\n",
      "\n",
      "Cross-validation results for Autoencoder Imputation:\n",
      "  Target: career_kills\n",
      "    Random Forest: 0.6296\n",
      "    Extra Trees Regressor: 0.5768\n",
      "    Gradient Boosting: 0.6132\n",
      "    Hist Gradient Boosting: 0.6288\n",
      "    Linear Regression: 0.3333\n",
      "    Ridge Regression: 0.3333\n",
      "    Lasso Regression: 0.3333\n",
      "    ElasticNet Regression: 0.3333\n",
      "    Support Vector Regressor: -0.0484\n",
      "    K-Neighbors Regressor: 0.5364\n",
      "    Decision Tree Regressor: 0.4160\n",
      "    AdaBoost Regressor: 0.1394\n",
      "    LightGBM Regressor: 0.6320\n",
      "    XGBoost Regressor: 0.5470\n",
      "  Target: career_wins\n",
      "    Random Forest: 0.4532\n",
      "    Extra Trees Regressor: 0.3753\n",
      "    Gradient Boosting: 0.4774\n",
      "    Hist Gradient Boosting: 0.4567\n",
      "    Linear Regression: 0.3676\n",
      "    Ridge Regression: 0.3676\n",
      "    Lasso Regression: 0.3676\n",
      "    ElasticNet Regression: 0.3676\n",
      "    Support Vector Regressor: -0.0039\n",
      "    K-Neighbors Regressor: 0.2345\n",
      "    Decision Tree Regressor: 0.0807\n",
      "    AdaBoost Regressor: 0.2974\n",
      "    LightGBM Regressor: 0.4504\n",
      "    XGBoost Regressor: 0.3718\n",
      "  Target: career_revives\n",
      "    Random Forest: 0.0128\n",
      "    Extra Trees Regressor: -0.0663\n",
      "    Gradient Boosting: 0.0928\n",
      "    Hist Gradient Boosting: 0.0622\n",
      "    Linear Regression: 0.1728\n",
      "    Ridge Regression: 0.1728\n",
      "    Lasso Regression: 0.1728\n",
      "    ElasticNet Regression: 0.1728\n",
      "    Support Vector Regressor: -0.0043\n",
      "    K-Neighbors Regressor: -0.0374\n",
      "    Decision Tree Regressor: -0.6968\n",
      "    AdaBoost Regressor: -0.2936\n",
      "    LightGBM Regressor: 0.0588\n",
      "    XGBoost Regressor: -0.1767\n",
      "\n",
      "Best imputation methods based on cross-validation:\n",
      "career_kills: Random Forest Imputation with Extra Trees Regressor (Score: 0.8098)\n",
      "career_wins: Random Forest Imputation with Extra Trees Regressor (Score: 0.8009)\n",
      "career_revives: Random Forest Imputation with Extra Trees Regressor (Score: 0.6798)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def cross_validate_imputation(imputed_df, target_column, models, n_splits=5):\n",
    "    X = imputed_df.drop(columns=[target_column])\n",
    "    y = imputed_df[target_column]\n",
    "    \n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    cv_scores = {name: [] for name in models.keys()}\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        for name, model in models.items():\n",
    "            model.fit(X_train, y_train)\n",
    "            score = model.score(X_test, y_test)\n",
    "            cv_scores[name].append(score)\n",
    "    \n",
    "    # Average scores for each model\n",
    "    avg_scores = {name: np.mean(scores) for name, scores in cv_scores.items()}\n",
    "    return avg_scores\n",
    "\n",
    "# Evaluate imputed datasets\n",
    "imputed_dataframes = {\n",
    "    \"Mode Imputation\": df_mode_imputed,\n",
    "    \"Logistic Regression Imputation\": df_lr_imputed,\n",
    "    \"Random Forest Imputation\": df_rf_imputed,\n",
    "    \"KNN Imputation (5 neighbors)\": df_knn_imputed_5,\n",
    "    \"KNN Imputation (10 neighbors)\": df_knn_imputed_10,\n",
    "    \"KNN Imputation (15 neighbors)\": df_knn_imputed_15,\n",
    "    \"Mean Imputation\": df_mean_imputed,\n",
    "    \"Median Imputation\": df_median_imputed,\n",
    "    \"XGBoost Imputation\": df_xgb_imputed,\n",
    "    \"MICE Imputation\": df_mice_imputed,\n",
    "    \"Autoencoder Imputation\": df_autoencoder_imputed\n",
    "}\n",
    "\n",
    "# Evaluate using cross-validation\n",
    "all_cv_results = {}\n",
    "for imputation_method, imputed_df in imputed_dataframes.items():\n",
    "    print(f\"\\nCross-validating {imputation_method} data...\")\n",
    "    imputed_df = imputed_df.drop(columns=['player_name'])\n",
    "    cv_results = {}\n",
    "    for target_column in target_columns:\n",
    "        print(f\"  Predicting {target_column}...\")\n",
    "        cv_scores = cross_validate_imputation(imputed_df, target_column, models)\n",
    "        cv_results[target_column] = cv_scores\n",
    "    all_cv_results[imputation_method] = cv_results\n",
    "\n",
    "# Print cross-validation results\n",
    "for imputation_method, cv_results in all_cv_results.items():\n",
    "    print(f\"\\nCross-validation results for {imputation_method}:\")\n",
    "    for target_column, model_scores in cv_results.items():\n",
    "        print(f\"  Target: {target_column}\")\n",
    "        for model_name, score in model_scores.items():\n",
    "            print(f\"    {model_name}: {score:.4f}\")\n",
    "\n",
    "# Find the best imputation method based on cross-validation\n",
    "best_imputation_methods = {}\n",
    "for target_column in target_columns:\n",
    "    best_score = float('-inf')\n",
    "    best_method = \"\"\n",
    "    best_model = \"\"\n",
    "    for imputation_method, cv_results in all_cv_results.items():\n",
    "        for model_name, score in cv_results[target_column].items():\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_method = imputation_method\n",
    "                best_model = model_name\n",
    "    best_imputation_methods[target_column] = (best_method, best_model, best_score)\n",
    "\n",
    "print(\"\\nBest imputation methods based on cross-validation:\")\n",
    "for target, (method, model, score) in best_imputation_methods.items():\n",
    "    print(f\"{target}: {method} with {model} (Score: {score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\altaa\\AppData\\Local\\Temp\\ipykernel_20360\\1001856044.py:1: DeprecationWarning: `import pandas_profiling` is going to be deprecated by April 1st. Please use `import ydata_profiling` instead.\n",
      "  from pandas_profiling import ProfileReport\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d63498805840c58fe1ad8a1493bc85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01fe233efcc3458b9e5cf0bce86da2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470859e652824e18aa6b84bb4f57d31a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53ecff0017a45d0b1c7dd7f47c483d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "Career_Stats_LR_Imputed_Data = pd.read_csv('C:/Users/altaa/Documents/GitHub/Apex-Legends-Research/Data_Retrieval/py_files/Notebook_For_Data_Preprocessing/Career_Stats_lr_imputed.csv', delimiter=',')\n",
    "df_report = ProfileReport(Career_Stats_LR_Imputed_Data, minimal=True)\n",
    "df_report.to_file(output_file='Career_Stats_For_LR_Imputed_Data.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
